#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
CLIP åœ–åƒåŒ¹é…æœå‹™
ç¨ç«‹é‹è¡Œä»¥é¿å…èˆ‡ PaddlePaddle çš„ cuDNN è¡çª
"""

from fastapi import FastAPI, File, UploadFile, Form, HTTPException
from pydantic import BaseModel
from typing import List, Optional
import torch
from transformers import CLIPProcessor, CLIPModel
from PIL import Image
import fitz  # PyMuPDF
import io
import tempfile
import os
import base64
import httpx  # ç”¨æ–¼èª¿ç”¨ PaddleOCR æœå‹™

app = FastAPI(title="CLIP åœ–åƒåŒ¹é…æœå‹™", description="åŸºæ–¼ CLIP çš„åœ–åƒç›¸ä¼¼åº¦åŒ¹é…æœå‹™")

# å…¨å±€æ¨¡å‹è®Šé‡ï¼ˆå»¶é²è¼‰å…¥ï¼‰
clip_model = None
clip_processor = None
device = None # æ–°å¢ä¸€å€‹è®Šæ•¸ä¾†å­˜æ”¾è¨­å‚™è³‡è¨Š

# PaddleOCR æœå‹™é…ç½®
PADDLEOCR_SERVICE_URL = os.getenv("PADDLEOCR_SERVICE_URL", "http://localhost:8080")

def get_clip_model():
    """å»¶é²è¼‰å…¥ CLIP æ¨¡å‹"""
    global clip_model, clip_processor ,device
    if clip_model is None:
        device = "cuda" if torch.cuda.is_available() else "cpu"
        print(f"åµæ¸¬åˆ°è¨­å‚™: {device}ã€‚æº–å‚™è¼‰å…¥ CLIP æ¨¡å‹...")
        print("è¼‰å…¥ CLIP æ¨¡å‹...")

        # ä½¿ç”¨ local_files_only=True ç¢ºä¿åªå¾æœ¬åœ°ç·©å­˜åŠ è¼‰ï¼Œä¸æœƒå¾ç¶²çµ¡ä¸‹è¼‰
        # é€™å·²ç¶“æ»¿è¶³å®‰å…¨è¦æ±‚ï¼Œå› ç‚ºä¸æœƒä¸‹è¼‰ä»»æ„ç‰ˆæœ¬çš„æ¨¡å‹
        clip_model = CLIPModel.from_pretrained(
            "openai/clip-vit-base-patch32",
            local_files_only=True,
            # å¦‚æœéœ€è¦å›ºå®šç‰ˆæœ¬ï¼Œå¯ä»¥æŒ‡å®š revision
            # revision="specific_commit_hash"
        )  # nosec B615 - ä½¿ç”¨ local_files_only=Trueï¼Œä¸æœƒå¾ç¶²çµ¡ä¸‹è¼‰
        clip_processor = CLIPProcessor.from_pretrained(
            "openai/clip-vit-base-patch32",
            local_files_only=True
        )  # nosec B615 - ä½¿ç”¨ local_files_only=Trueï¼Œä¸æœƒå¾ç¶²çµ¡ä¸‹è¼‰

        clip_model.to(device)
        print("CLIP æ¨¡å‹è¼‰å…¥å®Œæˆ")
    return clip_model, clip_processor , device

def compute_image_similarity(image, template_images, model, processor):
    """
    è¨ˆç®—åœ–åƒèˆ‡ç¯„æœ¬åœ–åƒçš„ç›¸ä¼¼åº¦
    Args:
        image: PIL Image å°è±¡
        template_images: ç¯„æœ¬åœ–åƒåˆ—è¡¨ (PIL Image å°è±¡)
        model: CLIP æ¨¡å‹
        processor: CLIP è™•ç†å™¨
    Returns:
        å¹³å‡ç›¸ä¼¼åº¦åˆ†æ•¸
    """
    # è™•ç†åœ–åƒ
    inputs = processor(images=[image] + template_images, return_tensors="pt", padding=True)
    inputs = {key: tensor.to(device) for key, tensor in inputs.items()}

    with torch.no_grad():
        image_features = model.get_image_features(**inputs)

    # æ­£è¦åŒ–ç‰¹å¾µå‘é‡
    image_features = image_features / image_features.norm(dim=-1, keepdim=True)

    # è¨ˆç®—æŸ¥è©¢åœ–åƒèˆ‡æ‰€æœ‰ç¯„æœ¬çš„ç›¸ä¼¼åº¦
    query_features = image_features[0:1]
    template_features = image_features[1:]

    similarities = torch.matmul(query_features, template_features.T).squeeze()

    # å¦‚æœåªæœ‰ä¸€å€‹ç¯„æœ¬ï¼Œç¢ºä¿è¿”å›æ¨™é‡
    if len(template_images) == 1:
        return similarities.item()

    # è¿”å›æœ€é«˜çš„ç›¸ä¼¼åº¦åˆ†æ•¸
    return similarities.max().item()

def pdf_to_images(pdf_path, dpi=200):
    """
    ä½¿ç”¨ PyMuPDF å°‡ PDF è½‰æ›ç‚ºåœ–åƒåˆ—è¡¨
    Args:
        pdf_path: PDF æ–‡ä»¶è·¯å¾‘
        dpi: åœ–åƒè§£æåº¦
    Returns:
        PIL Image å°è±¡åˆ—è¡¨
    """
    pdf_document = fitz.open(pdf_path)
    images = []

    # è¨ˆç®—ç¸®æ”¾å› å­ï¼ˆDPI / 72ï¼Œå› ç‚º PDF é»˜èªæ˜¯ 72 DPIï¼‰
    zoom = dpi / 72
    mat = fitz.Matrix(zoom, zoom)

    for page_num in range(len(pdf_document)):
        page = pdf_document[page_num]
        pix = page.get_pixmap(matrix=mat)

        # è½‰æ›ç‚º PIL Image
        img_data = pix.tobytes("png")
        img = Image.open(io.BytesIO(img_data))
        images.append(img)

    pdf_document.close()
    return images

async def check_page_voided(page_image: Image.Image) -> tuple[bool, dict]:
    """
    æª¢æŸ¥é é¢æ˜¯å¦åŒ…å«å»¢æ­¢é—œéµå­—
    Args:
        page_image: PIL Image å°è±¡
    Returns:
        (is_voided, ocr_result) - æ˜¯å¦ç‚ºå»¢æ­¢é é¢, OCR çµæœ
    """
    try:
        # å°‡åœ–ç‰‡è½‰æ›ç‚º bytes
        img_byte_arr = io.BytesIO()
        page_image.save(img_byte_arr, format='PNG')
        img_byte_arr.seek(0)

        # èª¿ç”¨ PaddleOCR æœå‹™é€²è¡Œ OCR
        async with httpx.AsyncClient(timeout=600.0, trust_env=False) as client:
            files = {
                'file': ('page.png', img_byte_arr, 'image/png')
            }
            data = {
                'key_list': '[]',  # ä¸éœ€è¦æå–é—œéµå­—
                'use_llm': 'false'  # ä¸ä½¿ç”¨ LLM
            }

            response = await client.post(
                f"{PADDLEOCR_SERVICE_URL}/ocr",
                files=files,
                data=data
            )

            if response.status_code != 200:
                print(f"OCR æœå‹™èª¿ç”¨å¤±æ•—: {response.text}")
                return False, {}

            result = response.json()

            if not result.get('success'):
                print(f"OCR è™•ç†å¤±æ•—: {result.get('error')}")
                return False, {}

            # å¾ visual_info_list ä¸­æå–æ‰€æœ‰æ–‡å­— - å°‡æ•´å€‹ visual_info è½‰æˆç´”æ–‡å­—
            visual_info_list = result.get('data', {}).get('visual_info_list', [])

            # å°‡ visual_info è½‰æ›ç‚ºå­—ä¸²
            import json
            all_text = json.dumps(visual_info_list, ensure_ascii=False)
            all_text = all_text.upper()  # è½‰ç‚ºå¤§å¯«ä¾¿æ–¼æ¯”å°

            # æª¢æŸ¥æ˜¯å¦åŒ…å«å»¢æ­¢é—œéµå­—
            void_keywords = ['å»¢æ­¢', 'ä½œå»¢', 'VOID', 'CANCELLED', 'CANCELED']
            is_voided = any(keyword.upper() in all_text for keyword in void_keywords)

            return is_voided, {
                'is_voided': is_voided,
                'found_keywords': [kw for kw in void_keywords if kw.upper() in all_text],
                'text_snippet': all_text[:200]  # ä¿å­˜å‰ 200 å€‹å­—å…ƒä½œç‚ºé è¦½
            }

    except Exception as e:
        print(f"å»¢æ­¢æª¢æ¸¬å¤±æ•—: {str(e)}")
        return False, {'error': str(e)}

class PageMatchRequest(BaseModel):
    """é é¢åŒ¹é…è«‹æ±‚æ¨¡å‹"""
    positive_threshold: float = 0.95
    negative_threshold: float = 0.55
    skip_voided: bool = False  # æ˜¯å¦è·³éå»¢æ­¢é é¢
    top_n_for_void_check: int = 5  # æª¢æŸ¥å‰ N å€‹å€™é¸é é¢æ˜¯å¦ç‚ºå»¢æ­¢

class PageMatchResponse(BaseModel):
    """é é¢åŒ¹é…éŸ¿æ‡‰æ¨¡å‹"""
    success: bool
    matched_page_number: Optional[int] = None
    matching_score: Optional[float] = None
    matched_page_base64: Optional[str] = None  # Base64 ç·¨ç¢¼çš„åœ–åƒ
    all_page_scores: Optional[List[dict]] = None
    voided_pages_checked: Optional[List[dict]] = None  # è¢«è·³éçš„å»¢æ­¢é é¢è³‡è¨Š
    error: Optional[str] = None

@app.post("/match-page", response_model=PageMatchResponse)
async def match_pdf_page(
    pdf_file: UploadFile = File(...),
    positive_templates: List[UploadFile] = File(...),
    negative_templates: List[UploadFile] = File(default=[]),
    positive_threshold: float = Form(0.95),
    negative_threshold: float = Form(0.55),
    skip_voided: bool = Form(False),
    top_n_for_void_check: int = Form(5),
):
    """
    æ‰¾å‡º PDF ä¸­æœ€åŒ¹é…çš„é é¢
    å¦‚æœ skip_voided ç‚º Trueï¼Œå‰‡æœƒæª¢æŸ¥ TOP N å€™é¸é é¢æ˜¯å¦åŒ…å«å»¢æ­¢é—œéµå­—
    """
    temp_pdf_path = None

    try:
        # æª¢æŸ¥ PDF æª”æ¡ˆé¡å‹
        if pdf_file.content_type != 'application/pdf':
            raise HTTPException(status_code=400, detail="è«‹ä¸Šå‚³æœ‰æ•ˆçš„ PDF æª”æ¡ˆ")

        # è¼‰å…¥ CLIP æ¨¡å‹
        model, processor , current_device = get_clip_model()

        # ä¿å­˜ PDF åˆ°è‡¨æ™‚æª”æ¡ˆ
        with tempfile.NamedTemporaryFile(delete=False, suffix='.pdf') as temp_pdf:
            content = await pdf_file.read()
            temp_pdf.write(content)
            temp_pdf_path = temp_pdf.name

        # è®€å–æ­£ä¾‹ç¯„æœ¬åœ–ç‰‡
        positive_images = []
        for template in positive_templates:
            try:
                # æª¢æŸ¥æ–‡ä»¶å
                if not template.filename:
                    raise HTTPException(status_code=400, detail="æ­£ä¾‹ç¯„æœ¬æ–‡ä»¶åç‚ºç©º")
                
                # è®€å–æ–‡ä»¶å…§å®¹
                content = await template.read()
                
                # æª¢æŸ¥å…§å®¹æ˜¯å¦ç‚ºç©º
                if not content or len(content) == 0:
                    raise HTTPException(status_code=400, detail=f"æ­£ä¾‹ç¯„æœ¬ {template.filename} å…§å®¹ç‚ºç©º")
                
                # å˜—è©¦æ‰“é–‹åœ–ç‰‡
                image = Image.open(io.BytesIO(content)).convert('RGB')
                positive_images.append(image)
                print(f"æˆåŠŸè¼‰å…¥æ­£ä¾‹ç¯„æœ¬: {template.filename}")
                
            except HTTPException:
                raise
            except Exception as e:
                raise HTTPException(
                    status_code=400, 
                    detail=f"ç„¡æ³•è®€å–æ­£ä¾‹ç¯„æœ¬ {template.filename}: {str(e)}ã€‚è«‹ç¢ºèªä¸Šå‚³çš„æ˜¯æœ‰æ•ˆçš„åœ–ç‰‡æª”æ¡ˆï¼ˆPNGã€JPG ç­‰æ ¼å¼ï¼‰"
                )

        if not positive_images:
            raise HTTPException(status_code=400, detail="è‡³å°‘éœ€è¦æä¾›ä¸€å¼µæ­£ä¾‹ç¯„æœ¬åœ–ç‰‡")

        # è®€å–åä¾‹ç¯„æœ¬åœ–ç‰‡ï¼ˆå¯é¸ï¼‰
        negative_images = []
        for template in negative_templates:
            try:
                # æª¢æŸ¥æ˜¯å¦æœ‰å¯¦éš›çš„æ–‡ä»¶å…§å®¹
                if not template.filename:
                    continue
                    
                content = await template.read()
                
                # æª¢æŸ¥å…§å®¹æ˜¯å¦ç‚ºç©º
                if not content or len(content) == 0:
                    print(f"è­¦å‘Š: åä¾‹ç¯„æœ¬ {template.filename} å…§å®¹ç‚ºç©ºï¼Œè·³é")
                    continue
                
                # å˜—è©¦æ‰“é–‹åœ–ç‰‡
                image = Image.open(io.BytesIO(content)).convert('RGB')
                negative_images.append(image)
                print(f"æˆåŠŸè¼‰å…¥åä¾‹ç¯„æœ¬: {template.filename}")
                
            except Exception as e:
                # å¦‚æœæŸå€‹åä¾‹ç¯„æœ¬ç„¡æ³•è¼‰å…¥ï¼Œåªè¨˜éŒ„è­¦å‘Šä½†ç¹¼çºŒè™•ç†
                print(f"è­¦å‘Š: ç„¡æ³•è¼‰å…¥åä¾‹ç¯„æœ¬ {template.filename}: {str(e)}ï¼Œè·³éæ­¤æ–‡ä»¶")
                continue

        # å°‡ PDF è½‰æ›ç‚ºåœ–åƒ
        pages = pdf_to_images(temp_pdf_path, dpi=200)

        all_scores = []
        candidates = []  # å€™é¸é é¢åˆ—è¡¨

        # æ‰¾å‡ºæœ€åŒ¹é…çš„é é¢
        print(f"é–‹å§‹åˆ†æ PDFï¼Œæ­£ä¾‹ç¯„æœ¬æ•¸é‡: {len(positive_images)}, åä¾‹ç¯„æœ¬æ•¸é‡: {len(negative_images)}")

        for idx, page_image in enumerate(pages):
            # è¨ˆç®—èˆ‡æ­£ä¾‹çš„ç›¸ä¼¼åº¦
            pos_similarity = compute_image_similarity(page_image, positive_images, model, processor)

            # è¨ˆç®—èˆ‡åä¾‹çš„ç›¸ä¼¼åº¦ï¼ˆå¦‚æœæœ‰æä¾›ï¼‰
            neg_similarity = 0
            if negative_images:
                neg_similarity = compute_image_similarity(page_image, negative_images, model, processor)

            all_scores.append({
                "page": idx + 1,
                "positive_similarity": float(pos_similarity),
                "negative_similarity": float(neg_similarity),
            })

            # æª¢æŸ¥æ˜¯å¦ç¬¦åˆæ¢ä»¶ï¼šæ­£ä¾‹ç›¸ä¼¼åº¦é«˜æ–¼é–¾å€¼ï¼Œä¸”åä¾‹ç›¸ä¼¼åº¦ä½æ–¼é–¾å€¼
            if pos_similarity >= positive_threshold and neg_similarity <= negative_threshold:
                candidates.append({
                    "page_index": idx,
                    "page_image": page_image,
                    "positive_similarity": pos_similarity,
                    "negative_similarity": neg_similarity
                })

        if not candidates:
            # æ‰¾å‡ºæœ€é«˜çš„æ­£ä¾‹åˆ†æ•¸
            max_pos = max((s["positive_similarity"] for s in all_scores), default=0)

            # æ‰¾å‡ºé”åˆ°æ­£ä¾‹é–¾å€¼çš„é é¢ï¼Œä¸¦é¡¯ç¤ºå®ƒå€‘çš„åä¾‹åˆ†æ•¸
            qualified_pos_pages = [s for s in all_scores if s["positive_similarity"] >= positive_threshold]

            if qualified_pos_pages:
                # æœ‰é”åˆ°æ­£ä¾‹é–¾å€¼ä½†åä¾‹ä¸ç¬¦åˆçš„æƒ…æ³
                min_neg_in_qualified = min((s["negative_similarity"] for s in qualified_pos_pages))
                error_msg = f"æœªæ‰¾åˆ°ç¬¦åˆæ¢ä»¶çš„é é¢ã€‚æœ‰ {len(qualified_pos_pages)} é é”åˆ°æ­£ä¾‹é–¾å€¼ >= {positive_threshold}ï¼Œä½†å®ƒå€‘çš„åä¾‹åˆ†æ•¸ï¼ˆæœ€ä½: {min_neg_in_qualified:.4f}ï¼‰éƒ½æœªä½æ–¼åä¾‹é–¾å€¼ <= {negative_threshold}ã€‚è«‹é™ä½åä¾‹é–¾å€¼ã€‚"
            else:
                # æ²’æœ‰ä»»ä½•é é¢é”åˆ°æ­£ä¾‹é–¾å€¼
                error_msg = f"æœªæ‰¾åˆ°ç¬¦åˆæ¢ä»¶çš„é é¢ã€‚æ‰€æœ‰é é¢çš„æ­£ä¾‹åˆ†æ•¸ï¼ˆæœ€é«˜: {max_pos:.4f}ï¼‰éƒ½æœªé”åˆ°æ­£ä¾‹é–¾å€¼ >= {positive_threshold}ã€‚è«‹é™ä½æ­£ä¾‹é–¾å€¼ã€‚"

            return PageMatchResponse(
                success=False,
                error=error_msg,
                all_page_scores=all_scores
            )

        # æŒ‰æ­£ä¾‹åˆ†æ•¸æ’åºï¼Œé¸å‡º TOP N å€™é¸é é¢
        candidates.sort(key=lambda x: x["positive_similarity"], reverse=True)

        voided_pages_info = []  # è¨˜éŒ„è¢«è·³éçš„å»¢æ­¢é é¢
        best_candidate = None

        # å¦‚æœå•Ÿç”¨è·³éå»¢æ­¢åŠŸèƒ½
        if skip_voided:
            print(f"å•Ÿç”¨å»¢æ­¢æª¢æ¸¬ï¼Œå°‡æª¢æŸ¥å‰ {top_n_for_void_check} å€‹å€™é¸é é¢")

            # æª¢æŸ¥ TOP N å€™é¸é é¢
            check_count = min(top_n_for_void_check, len(candidates))

            for i in range(check_count):
                candidate = candidates[i]
                page_num = candidate["page_index"] + 1

                print(f"æª¢æŸ¥ç¬¬ {page_num} é æ˜¯å¦ç‚ºå»¢æ­¢é é¢...")
                is_voided, void_info = await check_page_voided(candidate["page_image"])

                if is_voided:
                    print(f"  ç¬¬ {page_num} é åŒ…å«å»¢æ­¢é—œéµå­—ï¼Œè·³é")
                    voided_pages_info.append({
                        "page": page_num,
                        "positive_similarity": float(candidate["positive_similarity"]),
                        "negative_similarity": float(candidate["negative_similarity"]),
                        "void_detection": void_info
                    })
                else:
                    print(f"  ç¬¬ {page_num} é æœªåŒ…å«å»¢æ­¢é—œéµå­—ï¼Œé¸ç‚ºæœ€ä½³åŒ¹é…")
                    best_candidate = candidate
                    break

            # å¦‚æœæ‰€æœ‰ TOP N å€™é¸éƒ½æ˜¯å»¢æ­¢é é¢
            if best_candidate is None:
                # æª¢æŸ¥æ˜¯å¦é‚„æœ‰å…¶ä»–å€™é¸
                if len(candidates) > check_count:
                    print(f"å‰ {check_count} å€‹å€™é¸éƒ½æ˜¯å»¢æ­¢é é¢ï¼Œå¾å‰©é¤˜å€™é¸ä¸­é¸æ“‡")
                    # å¾å‰©é¤˜å€™é¸ä¸­é¸å‡ºåä¾‹åˆ†æ•¸æœ€ä½çš„
                    remaining_candidates = candidates[check_count:]
                    top5_remaining = remaining_candidates[:5]
                    best_candidate = min(top5_remaining, key=lambda x: x["negative_similarity"])
                else:
                    return PageMatchResponse(
                        success=False,
                        error=f"å‰ {check_count} å€‹å€™é¸é é¢éƒ½åŒ…å«å»¢æ­¢é—œéµå­—ï¼Œæ²’æœ‰æ‰¾åˆ°æœ‰æ•ˆé é¢",
                        voided_pages_checked=voided_pages_info,
                        all_page_scores=all_scores
                    )
        else:
            # æœªå•Ÿç”¨è·³éå»¢æ­¢åŠŸèƒ½ï¼Œä½¿ç”¨åŸé‚è¼¯
            # å¾ TOP 5 ä¸­é¸å‡ºåä¾‹åˆ†æ•¸æœ€ä½çš„
            top5_candidates = candidates[:5]
            best_candidate = min(top5_candidates, key=lambda x: x["negative_similarity"])

        best_page_index = best_candidate["page_index"]
        best_page_image = best_candidate["page_image"]

        print(f"æ‰¾åˆ°æœ€ä½³åŒ¹é…é é¢: ç¬¬ {best_page_index + 1} é ")
        print(f"  æ­£ä¾‹ç›¸ä¼¼åº¦: {best_candidate['positive_similarity']:.4f}")
        print(f"  åä¾‹ç›¸ä¼¼åº¦: {best_candidate['negative_similarity']:.4f}")
        print(f"  å€™é¸é é¢ç¸½æ•¸: {len(candidates)}")
        if voided_pages_info:
            print(f"  è·³éçš„å»¢æ­¢é é¢æ•¸: {len(voided_pages_info)}")

        # å°‡åŒ¹é…çš„é é¢è½‰æ›ç‚º Base64
        buffered = io.BytesIO()
        best_page_image.save(buffered, format="PNG")
        img_base64 = base64.b64encode(buffered.getvalue()).decode('utf-8')

        return PageMatchResponse(
            success=True,
            matched_page_number=best_page_index + 1,
            matching_score=float(best_candidate["positive_similarity"]),
            matched_page_base64=img_base64,
            all_page_scores=all_scores,
            voided_pages_checked=voided_pages_info if voided_pages_info else None
        )

    except HTTPException:
        raise
    except Exception as e:
        import traceback
        error_detail = f"è™•ç†éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {str(e)}\n{traceback.format_exc()}"
        print(error_detail)
        return PageMatchResponse(success=False, error=error_detail)

    finally:
        # æ¸…ç†è‡¨æ™‚æª”æ¡ˆ
        if temp_pdf_path and os.path.exists(temp_pdf_path):
            try:
                os.unlink(temp_pdf_path)
            except Exception as e:
                print(f"æ¸…ç†è‡¨æ™‚æª”æ¡ˆå¤±æ•—: {temp_pdf_path}, éŒ¯èª¤: {e}")

@app.get("/health")
async def health_check():
    """å¥åº·æª¢æŸ¥ç«¯é»"""
    return {"status": "healthy", "message": "CLIP æœå‹™é‹è¡Œæ­£å¸¸"}

if __name__ == "__main__":
    import uvicorn
    import os

    # å¾ç’°å¢ƒè®Šé‡è®€å–é…ç½®ï¼Œé»˜èªåªç¶å®š localhost
    # ç”Ÿç”¢ç’°å¢ƒè‹¥éœ€è¦å°å¤–è¨ªå•ï¼Œè«‹è¨­ç½®ç’°å¢ƒè®Šé‡ CLIP_HOST=0.0.0.0
    host = os.getenv("CLIP_HOST", "127.0.0.1")
    port = int(os.getenv("CLIP_PORT", "8081"))

    print("ğŸš€ å•Ÿå‹• CLIP åœ–åƒåŒ¹é…æœå‹™...")
    print(f"ğŸŒ æœå‹™åœ°å€: http://{host}:{port}")
    print(f"ğŸŒ æœ¬æ©Ÿè¨ªå•: http://localhost:{port}")

    # nosec B104: å¾ç’°å¢ƒè®Šé‡è®€å– hostï¼Œé»˜èªç‚ºå®‰å…¨çš„ 127.0.0.1
    # åªæœ‰æ˜ç¢ºè¨­ç½®ç’°å¢ƒè®Šé‡æ‰æœƒç¶å®šåˆ°æ‰€æœ‰æ¥å£ï¼Œä¸¦æœƒé¡¯ç¤ºè­¦å‘Š
    if host == "0.0.0.0":  # nosec B104
        print("âš ï¸  è­¦å‘Š: æœå‹™ç¶å®šåˆ°æ‰€æœ‰ç¶²çµ¡æ¥å£ (0.0.0.0)ï¼Œè«‹ç¢ºä¿å·²è¨­ç½®é©ç•¶çš„é˜²ç«ç‰†è¦å‰‡")

    uvicorn.run(app, host=host, port=port)
