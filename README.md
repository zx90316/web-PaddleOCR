# PaddleOCR æ–‡æª”è­˜åˆ¥ç¶²ç«™ / PaddleOCR Document Recognition Web Application

[English](#english) | [ç¹é«”ä¸­æ–‡](#ç¹é«”ä¸­æ–‡)

---

## ç¹é«”ä¸­æ–‡

ä¸€å€‹åŸºæ–¼ FastAPI å’Œ PaddleOCR çš„æ–‡æª”è­˜åˆ¥ç¶²ç«™ï¼Œæ”¯æ´åœ–ç‰‡å’Œ PDF æª”æ¡ˆçš„æ–‡å­—è­˜åˆ¥èˆ‡é—œéµå­—æå–ã€‚

## åŠŸèƒ½ç‰¹è‰²

- ğŸ–¼ï¸ æ”¯æ´å¤šç¨®åœ–ç‰‡æ ¼å¼ä¸Šå‚³ï¼ˆJPGã€PNGã€BMPç­‰ï¼‰
- ğŸ“„ æ”¯æ´ PDF æª”æ¡ˆä¸Šå‚³å’Œå¤šé è™•ç†
- ğŸ” åŸºæ–¼ PaddleOCR çš„é«˜ç²¾åº¦æ–‡å­—è­˜åˆ¥
- ğŸ’¬ æ™ºæ…§é—œéµå­—æå–åŠŸèƒ½
- ğŸ·ï¸ é è¨­é—œéµå­—å¿«é€Ÿé¸æ“‡ï¼ˆè»Šè¼›ã€è­‰ä»¶ã€å…¬å¸ã€ç™¼ç¥¨ç­‰åˆ†é¡ï¼‰
- ğŸ‘ï¸ å®Œæ•´çš„åœ–ç‰‡è­˜åˆ¥è³‡è¨Šé¡¯ç¤ºï¼ˆåŒ…å«æ–‡å­—å€å¡Šå’Œåº§æ¨™ï¼‰
- ğŸ“‘ å¤šé é¢æ–‡ä»¶æ”¯æ´
- ğŸŒ ç°¡æ½”ç¾è§€çš„ç¶²é ä»‹é¢
- ğŸ“Š JSON æ ¼å¼çš„çµæ§‹åŒ–å›æ‡‰
- âš™ï¸ å¯èª¿æ•´çš„è™•ç†è¨­å®šé¸é …

## å®‰è£æ­¥é©Ÿ

**é‡è¦ï¼šæœ¬å°ˆæ¡ˆä½¿ç”¨é›™æœå‹™æ¶æ§‹ä»¥é¿å… PyTorch å’Œ PaddlePaddle çš„ cuDNN è¡çªã€‚**

### æ–¹æ³•ä¸€ï¼šä½¿ç”¨å•Ÿå‹•è…³æœ¬ï¼ˆæ¨è–¦ï¼‰

1. å‰µå»ºå…©å€‹è™›æ“¬ç’°å¢ƒä¸¦å®‰è£ä¾è³´ï¼š

```bash
# CLIP æœå‹™ç’°å¢ƒ
python -m venv venv_clip
venv_clip\Scripts\activate  # Windows
# source venv_clip/bin/activate  # Linux/Mac
pip install -r requirements_clip.txt
deactivate

# PaddleOCR æœå‹™ç’°å¢ƒ
python -m venv venv_paddle
venv_paddle\Scripts\activate  # Windows
# source venv_paddle/bin/activate  # Linux/Mac
pip install -r requirements_paddle.txt
deactivate
```

2. å®‰è£ä¸¦å•Ÿå‹• Ollamaï¼ˆç”¨æ–¼ LLM é—œéµå­—æå–ï¼‰ï¼š

```bash
# ä¸‹è¼‰ä¸¦å®‰è£ Ollama: https://ollama.ai
ollama serve

# åœ¨å¦ä¸€å€‹çµ‚ç«¯ä¸‹è¼‰æ¨¡å‹
ollama pull gemma3:4b
```

3. é…ç½® LLM è¨­å®šï¼ˆå¯é¸ï¼‰ï¼š

ç·¨è¼¯ `PP-ChatOCRv4-doc.yaml` ä¸­çš„ LLM é…ç½®ï¼š
```yaml
SubModules:
  LLM_Chat:
    module_name: chat_bot
    model_name: gemma3:4b  # ä¿®æ”¹ç‚ºæ‚¨ä½¿ç”¨çš„æ¨¡å‹
    base_url: "http://localhost:11434/v1"  # Ollama API ç«¯é»
    api_type: openai
    api_key: "sk-123456789"
```

4. ä½¿ç”¨å•Ÿå‹•è…³æœ¬å•Ÿå‹•å…©å€‹æœå‹™ï¼š

```bash
python start_services.py
```

é€™å°‡è‡ªå‹•å•Ÿå‹•ï¼š
- CLIP æœå‹™ï¼ˆPort 8081ï¼‰
- PaddleOCR æœå‹™ï¼ˆPort 8080ï¼‰

### æ–¹æ³•äºŒï¼šæ‰‹å‹•å•Ÿå‹•

åœ¨å…©å€‹ä¸åŒçš„çµ‚ç«¯ä¸­åˆ†åˆ¥å•Ÿå‹•æœå‹™ï¼š

```bash
# çµ‚ç«¯ 1: CLIP æœå‹™
venv_clip\Scripts\activate
python clip_service.py

# çµ‚ç«¯ 2: PaddleOCR æœå‹™
venv_paddle\Scripts\activate
python app.py
```

## ä½¿ç”¨æ–¹æ³•

1. é–‹å•Ÿç€è¦½å™¨è¨ªå•ï¼š
```
http://localhost:8080         # ä¸»é é¢
http://localhost:8080/admin   # ç®¡ç†å¾Œå°
http://localhost:8080/batch-tasks  # æ‰¹æ¬¡è™•ç†
```

2. åœ¨ç¶²é ä¸Šï¼š
   - é¸æ“‡è¦è­˜åˆ¥çš„åœ–ç‰‡æˆ–PDFæª”æ¡ˆ
   - è¼¸å…¥éœ€è¦æå–çš„é—œéµå­—ï¼ˆæ¯è¡Œä¸€å€‹ï¼‰
   - é¸æ“‡æ˜¯å¦ä½¿ç”¨æ–‡æª”æ–¹å‘åˆ†é¡å’Œå»å½æ›²åŠŸèƒ½
   - é»æ“Šã€Œä¸Šå‚³ä¸¦è­˜åˆ¥ã€æŒ‰éˆ•

3. ç³»çµ±æœƒè¿”å›åŒ…å«æå–çµæœçš„ JSON è³‡æ–™

## API ç«¯é»

### GET /
è¿”å›ç¶²ç«™é¦–é 

### POST /ocr
è™•ç†åœ–ç‰‡ OCR è«‹æ±‚

**è«‹æ±‚åƒæ•¸ï¼š**
- `file`: åœ–ç‰‡æˆ–PDFæª”æ¡ˆ
- `key_list`: JSON æ ¼å¼çš„é—œéµå­—åˆ—è¡¨
- `use_doc_orientation_classify`: æ˜¯å¦ä½¿ç”¨æ–‡æª”æ–¹å‘åˆ†é¡ï¼ˆå¸ƒæ—å€¼ï¼‰
- `use_doc_unwarping`: æ˜¯å¦ä½¿ç”¨æ–‡æª”å»å½æ›²ï¼ˆå¸ƒæ—å€¼ï¼‰

**å›æ‡‰æ ¼å¼ï¼š**
```json
{
  "success": true,
  "data": {
    "chat_result": {
      // é—œéµå­—æå–çµæœ
    },
    "visual_info_list": [
      {
        "image_width": 1024,
        "image_height": 768,
        "text_regions": [
          {
            "text": "è­˜åˆ¥åˆ°çš„æ–‡å­—",
            "points": [{"x": 100, "y": 200}, ...]
          }
        ]
      }
    ],
    "key_list": ["é—œéµå­—1", "é—œéµå­—2"],
    "settings": {
      "use_doc_orientation_classify": false,
      "use_doc_unwarping": false
    }
  },
  "error": null
}
```

### GET /health
å¥åº·æª¢æŸ¥ç«¯é»

## é…ç½®èªªæ˜

### LLM é…ç½®

ç·¨è¼¯ `PP-ChatOCRv4-doc.yaml` ä¾†é…ç½® LLM æœå‹™ï¼š

```yaml
SubModules:
  LLM_Chat:
    module_name: chat_bot
    model_name: gemma3:4b  # æ¨¡å‹åç¨±
    base_url: "http://localhost:11434/v1"  # Ollama API ç«¯é»
    api_type: openai
    api_key: "sk-123456789"  # API é‡‘é‘°ï¼ˆæœ¬åœ° Ollama å¯ä»¥æ˜¯ä»»æ„å€¼ï¼‰
```

æ”¯æ´çš„æ¨¡å‹ï¼š
- `gemma3:4b`ï¼ˆæ¨è–¦ï¼Œè¼ƒå¿«ï¼‰
- `llama3:8b`
- `qwen2.5:7b`
- å…¶ä»–æ”¯æ´ OpenAI API æ ¼å¼çš„æ¨¡å‹

### CLIP æœå‹™é…ç½®

é€šéç’°å¢ƒè®Šæ•¸é…ç½® CLIP æœå‹™ URLï¼ˆå¯é¸ï¼‰ï¼š

```bash
export CLIP_SERVICE_URL=http://localhost:8081  # Linux/Mac
set CLIP_SERVICE_URL=http://localhost:8081     # Windows
```

## æ³¨æ„äº‹é …

- **å¿…é ˆå•Ÿå‹• Ollama æœå‹™**æ‰èƒ½ä½¿ç”¨é—œéµå­—æå–åŠŸèƒ½ï¼ˆ`use_llm=True`ï¼‰
- ç¢ºä¿ PaddleOCR å’Œç›¸é—œä¾è³´æ­£ç¢ºå®‰è£åœ¨å„è‡ªçš„è™›æ“¬ç’°å¢ƒä¸­
- æ”¯æ´çš„æª”æ¡ˆæ ¼å¼ï¼šJPGã€PNGã€BMP ç­‰åœ–ç‰‡æ ¼å¼ä»¥åŠ PDF æª”æ¡ˆ
- è‡¨æ™‚æª”æ¡ˆæœƒåœ¨è™•ç†å®Œæˆå¾Œè‡ªå‹•æ¸…ç†
- PDF é é¢åŒ¹é…éœ€è¦å…©å€‹æœå‹™éƒ½åœ¨é‹è¡Œ

## æ•…éšœæ’é™¤

å¦‚æœé‡åˆ°å•é¡Œï¼Œè«‹æª¢æŸ¥ï¼š

1. **Ollama ç›¸é—œ**
   - Ollama æœå‹™æ˜¯å¦æ­£åœ¨é‹è¡Œï¼š`ollama serve`
   - æ¨¡å‹æ˜¯å¦å·²ä¸‹è¼‰ï¼š`ollama list`
   - API ç«¯é»æ˜¯å¦æ­£ç¢ºï¼šæª¢æŸ¥ `PP-ChatOCRv4-doc.yaml` ä¸­çš„ `base_url`

2. **æœå‹™å•Ÿå‹•å•é¡Œ**
   - ç¢ºèªè™›æ“¬ç’°å¢ƒå·²æ­£ç¢ºå‰µå»ºä¸¦å®‰è£ä¾è³´
   - ç¢ºèªç«¯å£ 8080 å’Œ 8081 æœªè¢«ä½”ç”¨
   - æª¢æŸ¥ CLIP æœå‹™æ˜¯å¦å•Ÿå‹•æˆåŠŸ

3. **cuDNN è¡çª**
   - ç¢ºä¿ PyTorch å’Œ PaddlePaddle åœ¨ä¸åŒçš„è™›æ“¬ç’°å¢ƒä¸­
   - ä½¿ç”¨ `requirements_clip.txt` å’Œ `requirements_paddle.txt` åˆ†åˆ¥å®‰è£

4. **å…¶ä»–å•é¡Œ**
   - æª¢æŸ¥æª”æ¡ˆæ ¼å¼æ˜¯å¦æ”¯æ´
   - ç¢ºèªç¶²è·¯é€£ç·šæ­£å¸¸
   - æŸ¥çœ‹æ§åˆ¶å°éŒ¯èª¤è¨Šæ¯

## æˆæ¬Šè²æ˜

æœ¬é …ç›®æ¡ç”¨ MIT æˆæ¬Šã€‚è©³ç´°è³‡è¨Šè«‹è¦‹ [LICENSE](LICENSE) æª”æ¡ˆã€‚

### ç¬¬ä¸‰æ–¹æˆæ¬Š

æœ¬é …ç›®ä½¿ç”¨äº†ä»¥ä¸‹é–‹æºè»Ÿé«”ï¼š

- **PaddleOCR** - Apache License 2.0
  - ç‰ˆæ¬Šæ‰€æœ‰ (c) 2020 PaddlePaddle Authors
  - å®˜æ–¹ç¶²ç«™ï¼šhttps://github.com/PaddlePaddle/PaddleOCR
  - æˆæ¬Šè©³æƒ…ï¼šhttps://github.com/PaddlePaddle/PaddleOCR/blob/release/2.7/LICENSE

### è‡´è¬

- æ„Ÿè¬ PaddlePaddle åœ˜éšŠæä¾›å„ªç§€çš„ OCR è§£æ±ºæ–¹æ¡ˆ
- æœ¬é …ç›®åƒ…ç‚º PaddleOCR çš„ç¶²é ç•Œé¢å°è£ï¼Œæ ¸å¿ƒ OCR åŠŸèƒ½ç”± PaddleOCR æä¾›

## å…è²¬è²æ˜

æœ¬è»Ÿé«”æŒ‰ã€Œç¾ç‹€ã€æä¾›ï¼Œä¸æä¾›ä»»ä½•æ˜ç¤ºæˆ–æš—ç¤ºçš„ä¿è­‰ã€‚ä½¿ç”¨æœ¬è»Ÿé«”æ‰€ç”¢ç”Ÿçš„ä»»ä½•å¾Œæœï¼Œä½œè€…ä¸æ‰¿æ“”è²¬ä»»ã€‚

---

## English

A web-based document recognition application built with FastAPI and PaddleOCR, supporting image and PDF file text recognition with keyword extraction.

## Features

- ğŸ–¼ï¸ Support for multiple image formats (JPG, PNG, BMP, etc.)
- ğŸ“„ PDF file upload and multi-page processing
- ğŸ” High-precision text recognition based on PaddleOCR
- ğŸ’¬ Intelligent keyword extraction with LLM
- ğŸ·ï¸ Preset keyword categories (vehicles, documents, companies, invoices, etc.)
- ğŸ‘ï¸ Complete OCR information display (text blocks and coordinates)
- ğŸ“‘ Multi-page document support
- ğŸŒ Clean and beautiful web interface
- ğŸ“Š Structured JSON responses
- âš™ï¸ Adjustable processing settings
- ğŸ”„ Batch processing for large-scale PDF operations
- ğŸ“¤ Excel export for batch results

## Installation

**Important: This project uses a dual-service architecture to avoid cuDNN conflicts between PyTorch and PaddlePaddle.**

### Method 1: Using Startup Script (Recommended)

1. Create two virtual environments and install dependencies:

```bash
# CLIP service environment
python -m venv venv_clip
venv_clip\Scripts\activate  # Windows
# source venv_clip/bin/activate  # Linux/Mac
pip install -r requirements_clip.txt
deactivate

# PaddleOCR service environment
python -m venv venv_paddle
venv_paddle\Scripts\activate  # Windows
# source venv_paddle/bin/activate  # Linux/Mac
pip install -r requirements_paddle.txt
deactivate
```

2. Install and start Ollama (for LLM keyword extraction):

```bash
# Download and install Ollama: https://ollama.ai
ollama serve

# In another terminal, download the model
ollama pull gemma3:4b
```

3. Configure LLM settings (optional):

Edit the LLM configuration in `PP-ChatOCRv4-doc.yaml`:
```yaml
SubModules:
  LLM_Chat:
    module_name: chat_bot
    model_name: gemma3:4b  # Change to your preferred model
    base_url: "http://localhost:11434/v1"  # Ollama API endpoint
    api_type: openai
    api_key: "sk-123456789"
```

4. Start both services using the startup script:

```bash
python start_services.py
```

This will automatically start:
- CLIP service (Port 8081)
- PaddleOCR service (Port 8080)

### Method 2: Manual Startup

Start services in two separate terminals:

```bash
# Terminal 1: CLIP service
venv_clip\Scripts\activate
python clip_service.py

# Terminal 2: PaddleOCR service
venv_paddle\Scripts\activate
python app.py
```

## Usage

1. Open your browser and visit:
```
http://localhost:8080              # Main page
http://localhost:8080/admin        # Admin dashboard
http://localhost:8080/batch-tasks  # Batch processing
```

2. On the web page:
   - Select an image or PDF file to recognize
   - Enter keywords to extract (one per line)
   - Choose whether to use document orientation classification and unwarping
   - Click the "Upload and Recognize" button

3. The system will return JSON data containing extraction results

## API Endpoints

### Single File Processing

**GET /** - Homepage

**POST /ocr** - Main OCR processing endpoint
- Accepts: image files or PDF
- Form parameters:
  - `file`: Image or PDF file
  - `key_list`: JSON array of keywords
  - `use_doc_orientation_classify`: Boolean
  - `use_doc_unwarping`: Boolean
  - `use_textline_orientation`: Boolean
  - `use_seal_recognition`: Boolean
  - `use_table_recognition`: Boolean
  - `use_llm`: Boolean

**POST /ocr-with-matching** - PDF page matching + OCR
- Accepts: PDF file, positive templates, negative templates
- Additional parameters:
  - `positive_threshold`: float (default: 0.25)
  - `negative_threshold`: float (default: 0.30)

### Batch Processing

**GET /batch-tasks** - Batch task management UI

**POST /api/batch-tasks/create** - Create batch task and scan directory

**POST /api/batch-tasks/{task_id}/stage1/config** - Configure CLIP matching parameters

**POST /api/batch-tasks/{task_id}/stage2/config** - Configure OCR parameters and keywords

**POST /api/batch-tasks/{task_id}/stage1/start** - Start Stage 1 processing

**POST /api/batch-tasks/{task_id}/stage2/start** - Start Stage 2 processing

**GET /api/batch-tasks/{task_id}/export** - Export results to Excel

**GET /health** - Health check endpoint

## Configuration

### LLM Configuration

Edit `PP-ChatOCRv4-doc.yaml` to configure the LLM service:

```yaml
SubModules:
  LLM_Chat:
    module_name: chat_bot
    model_name: gemma3:4b  # Model name
    base_url: "http://localhost:11434/v1"  # Ollama API endpoint
    api_type: openai
    api_key: "sk-123456789"  # API key (can be any value for local Ollama)
```

Supported models:
- `gemma3:4b` (recommended, faster)
- `llama3:8b`
- `qwen2.5:7b`
- Any model supporting OpenAI API format

### CLIP Service Configuration

Configure CLIP service URL via environment variable (optional):

```bash
export CLIP_SERVICE_URL=http://localhost:8081  # Linux/Mac
set CLIP_SERVICE_URL=http://localhost:8081     # Windows
```

## Important Notes

- **Ollama service must be running** to use keyword extraction (`use_llm=True`)
- Ensure PaddleOCR and dependencies are correctly installed in separate virtual environments
- Supported file formats: JPG, PNG, BMP images and PDF files
- Temporary files are cleaned up after processing
- PDF page matching requires both services running
- Batch processing runs in background threads with progress tracking

## Troubleshooting

If you encounter issues:

1. **Ollama Related**
   - Check if Ollama service is running: `ollama serve`
   - Check if model is downloaded: `ollama list`
   - Verify API endpoint in `PP-ChatOCRv4-doc.yaml`

2. **Service Startup Issues**
   - Confirm virtual environments are created and dependencies installed
   - Check if ports 8080 and 8081 are available
   - Verify CLIP service started successfully

3. **cuDNN Conflicts**
   - Ensure PyTorch and PaddlePaddle are in separate virtual environments
   - Use `requirements_clip.txt` and `requirements_paddle.txt` separately

4. **Other Issues**
   - Check file format compatibility
   - Verify network connection
   - Review console error messages

## Architecture

**Dual-Service Architecture:**

1. **PaddleOCR Service** (app.py, Port 8080)
   - Main FastAPI application
   - Handles OCR processing with PaddleOCR
   - Manages batch processing tasks
   - Calls CLIP service for PDF page matching

2. **CLIP Service** (clip_service.py, Port 8081)
   - Independent image matching service
   - Uses PyTorch + CLIP model
   - Provides `/match-page` endpoint for PDF page matching

**Databases:**
- `ocr_tasks.db` - Single OCR task history
- `batch_tasks.db` - Batch processing tasks and files

## License

This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for details.

### Third-Party Licenses

This project uses the following open-source software:

- **PaddleOCR** - Apache License 2.0
  - Copyright (c) 2020 PaddlePaddle Authors
  - Official website: https://github.com/PaddlePaddle/PaddleOCR
  - License details: https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.7/LICENSE

### Acknowledgments

- Thanks to the PaddlePaddle team for providing excellent OCR solutions
- This project is a web interface wrapper for PaddleOCR; core OCR functionality is provided by PaddleOCR

## Disclaimer

This software is provided "as is," without warranty of any kind, express or implied. The author assumes no responsibility for any consequences arising from the use of this software.