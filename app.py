#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
PaddleOCR Web Interface
Copyright (c) 2025

This project provides a web interface for PaddleOCR.
This software uses PaddleOCR, which is licensed under Apache License 2.0.

PaddleOCR Copyright (c) 2020 PaddlePaddle Authors. All Rights Reserved.
Licensed under the Apache License, Version 2.0.
See: https://github.com/PaddlePaddle/PaddleOCR

æœ¬é …ç›®åƒ…ç‚º PaddleOCR çš„ç¶²é ç•Œé¢å°è£ï¼Œæ ¸å¿ƒ OCR åŠŸèƒ½ç”± PaddleOCR æä¾›ã€‚
"""

from fastapi import FastAPI, File, UploadFile, Form, HTTPException, Request
from fastapi.responses import HTMLResponse
from fastapi.staticfiles import StaticFiles
from fastapi.templating import Jinja2Templates
from pydantic import BaseModel
from typing import List, Optional
import json
import os
import tempfile
from paddlex import create_pipeline
import shutil
import numpy as np
from PIL import Image
import io
import uuid
from datetime import datetime
import database
import httpx  # ç”¨æ–¼èª¿ç”¨ CLIP æœå‹™
import base64
import task_database as batch_db
import batch_processor
from urllib.parse import quote
import logging
from logging.handlers import RotatingFileHandler

# ==================== æ—¥èªŒé…ç½® ====================
# å»ºç«‹ logs ç›®éŒ„
os.makedirs("logs", exist_ok=True)

# é…ç½®æ‡‰ç”¨ç¨‹å¼æ—¥èªŒ
logger = logging.getLogger("paddleocr_app")
logger.setLevel(logging.INFO)

# æª”æ¡ˆè™•ç†å™¨ - ä½¿ç”¨è¼ªæ›¿æ©Ÿåˆ¶ (æ¯å€‹æª”æ¡ˆ 10MB, ä¿ç•™ 10 å€‹å‚™ä»½)
file_handler = RotatingFileHandler(
    "logs/app.log",
    maxBytes=10*1024*1024,  # 10MB
    backupCount=10,
    encoding='utf-8'
)
file_handler.setFormatter(logging.Formatter(
    '%(asctime)s - %(name)s - %(levelname)s - [%(filename)s:%(lineno)d] - %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
))
logger.addHandler(file_handler)

# ä¸»æ§å°è™•ç†å™¨
console_handler = logging.StreamHandler()
console_handler.setFormatter(logging.Formatter(
    '%(asctime)s - %(levelname)s - %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
))
logger.addHandler(console_handler)

logger.info("=" * 60)
logger.info("PaddleOCR æ‡‰ç”¨ç¨‹å¼æ—¥èªŒç³»çµ±å·²åˆå§‹åŒ–")
logger.info("=" * 60)

# ==================== FastAPI æ‡‰ç”¨ç¨‹å¼åˆå§‹åŒ– ====================

# åˆå§‹åŒ– FastAPI æ‡‰ç”¨ç¨‹å¼
app = FastAPI(title="PaddleOCR åœ–ç‰‡è­˜åˆ¥æœå‹™", description="ä¸Šå‚³åœ–ç‰‡ä¸¦æå–æŒ‡å®šçš„é—œéµå­—")

# è¨­å®šéœæ…‹æª”æ¡ˆæœå‹™
output_dir = "output"
os.makedirs(output_dir, exist_ok=True)

# åˆå§‹åŒ–è³‡æ–™åº«
database.init_database()
batch_db.init_database()

app.mount("/static", StaticFiles(directory="static"), name="static")
app.mount("/output", StaticFiles(directory=output_dir), name="output")

# è¨­å®šæ¨¡æ¿å¼•æ“
templates = Jinja2Templates(directory="templates")

# åˆå§‹åŒ– PaddleOCR ç®¡ç·š
pipeline = create_pipeline(
    pipeline="./PP-ChatOCRv4-doc.yaml",
    initial_predictor=False
    )

# CLIP æœå‹™é…ç½®
CLIP_SERVICE_URL = os.getenv("CLIP_SERVICE_URL", "http://192.168.80.24:8081")

# MLLM æœå‹™é…ç½®
MLLM_SERVICE_URL = os.getenv("MLLM_SERVICE_URL", "http://localhost:8080")

async def check_mllm_health() -> bool:
    """
    æª¢æŸ¥å¤šæ¨¡æ…‹å¤§æ¨¡å‹æœå‹™æ˜¯å¦é‹è¡Œä¸­
    Returns:
        bool: True è¡¨ç¤ºæœå‹™æ­£å¸¸ï¼ŒFalse è¡¨ç¤ºæœå‹™ä¸å¯ç”¨
    """
    try:
        async with httpx.AsyncClient(timeout=5.0) as client:
            response = await client.get(f"{MLLM_SERVICE_URL}/health")
            if response.status_code == 200:
                data = response.json()
                # æª¢æŸ¥ errorCode æ˜¯å¦ç‚º 0 è¡¨ç¤ºå¥åº·
                if data.get("errorCode") == 0:
                    logger.info(f"MLLM æœå‹™å¥åº·æª¢æŸ¥é€šé: {data.get('errorMsg', 'Healthy')}")
                    return True
                else:
                    logger.warning(f"MLLM æœå‹™å›æ‡‰ç•°å¸¸: errorCode={data.get('errorCode')}, errorMsg={data.get('errorMsg')}")
                    return False
            else:
                logger.warning(f"MLLM æœå‹™å¥åº·æª¢æŸ¥å¤±æ•—: HTTP {response.status_code}")
                return False
    except httpx.TimeoutException:
        logger.error("MLLM æœå‹™å¥åº·æª¢æŸ¥è¶…æ™‚")
        return False
    except Exception as e:
        logger.error(f"MLLM æœå‹™å¥åº·æª¢æŸ¥éŒ¯èª¤: {str(e)}")
        return False

# è«‹æ±‚æ¨¡å‹
class OCRRequest(BaseModel):
    key_list: List[str]
    use_doc_orientation_classify: Optional[bool] = False
    use_doc_unwarping: Optional[bool] = False

# éŸ¿æ‡‰æ¨¡å‹
class OCRResponse(BaseModel):
    success: bool
    data: Optional[dict] = None
    error: Optional[str] = None

async def call_clip_service(pdf_file_path: str, positive_templates: List[UploadFile], negative_templates: List[UploadFile], positive_threshold: float, negative_threshold: float, skip_voided: bool = False, top_n_for_void_check: int = 5):
    """
    èª¿ç”¨ CLIP æœå‹™é€²è¡Œé é¢åŒ¹é…
    Args:
        pdf_file_path: PDF æ–‡ä»¶è·¯å¾‘
        positive_templates: æ­£ä¾‹ç¯„æœ¬åœ–ç‰‡åˆ—è¡¨
        negative_templates: åä¾‹ç¯„æœ¬åœ–ç‰‡åˆ—è¡¨
        positive_threshold: æ­£ä¾‹ç›¸ä¼¼åº¦é–¾å€¼
        negative_threshold: åä¾‹ç›¸ä¼¼åº¦é–¾å€¼
        skip_voided: æ˜¯å¦è·³éå»¢æ­¢é é¢
        top_n_for_void_check: æª¢æŸ¥å‰ N å€‹å€™é¸é é¢æ˜¯å¦ç‚ºå»¢æ­¢
    Returns:
        (matched_page_number, matched_page_image, matching_score, all_scores, voided_pages_checked)
    """
    async with httpx.AsyncClient(timeout=600.0, trust_env=False) as client:
        # æº–å‚™æ–‡ä»¶
        files = []

        # PDF æ–‡ä»¶
        with open(pdf_file_path, 'rb') as f:
            files.append(('pdf_file', (os.path.basename(pdf_file_path), f.read(), 'application/pdf')))

        # æ­£ä¾‹ç¯„æœ¬
        for template in positive_templates:
            await template.seek(0)  # é‡ç½®æ–‡ä»¶æŒ‡é‡
            content = await template.read()
            files.append(('positive_templates', (template.filename, content, template.content_type)))

        # åä¾‹ç¯„æœ¬
        for template in negative_templates:
            await template.seek(0)
            content = await template.read()
            files.append(('negative_templates', (template.filename, content, template.content_type)))

        # æº–å‚™è¡¨å–®æ•¸æ“š
        data = {
            'positive_threshold': positive_threshold,
            'negative_threshold': negative_threshold,
            'skip_voided': skip_voided,
            'top_n_for_void_check': top_n_for_void_check
        }

        # èª¿ç”¨ CLIP æœå‹™
        response = await client.post(
            f"{CLIP_SERVICE_URL}/match-page",
            files=files,
            data=data
        )

        if response.status_code != 200:
            raise HTTPException(status_code=500, detail=f"CLIP æœå‹™èª¿ç”¨å¤±æ•—: {response.text}")

        result = response.json()

        if not result.get('success'):
            raise HTTPException(status_code=400, detail=result.get('error', 'æœªçŸ¥éŒ¯èª¤'))

        # è§£ç¢¼ Base64 åœ–åƒ
        matched_page_image = None
        if result.get('matched_page_base64'):
            img_data = base64.b64decode(result['matched_page_base64'])
            matched_page_image = Image.open(io.BytesIO(img_data))

        return (
            result.get('matched_page_number'),
            matched_page_image,
            result.get('matching_score'),
            result.get('all_page_scores', []),
            result.get('voided_pages_checked', [])
        )

async def perform_ocr_on_file(
    file_path: str,
    key_list_parsed: list,
    original_filename: str,
    task_output_dir: str,
    use_doc_orientation_classify: bool = False,
    use_doc_unwarping: bool = False,
    use_textline_orientation: bool = False,
    use_seal_recognition: bool = False,
    use_table_recognition: bool = True,
    use_llm: bool = True,
    use_mllm: bool = False,
):
    """
    å°æª”æ¡ˆåŸ·è¡Œ OCR è™•ç†çš„æ ¸å¿ƒé‚è¼¯
    Args:
        file_path: åœ–ç‰‡æˆ–PDFæª”æ¡ˆè·¯å¾‘
        key_list_parsed: å·²è§£æçš„é—œéµå­—åˆ—è¡¨
        original_filename: åŸå§‹æª”æ¡ˆå
        task_output_dir: ä»»å‹™å°ˆå±¬çš„è¼¸å‡ºç›®éŒ„
        å…¶ä»–åƒæ•¸: OCR è™•ç†é¸é …
    Returns:
        è™•ç†çµæœå­—å…¸
    """
    # å¦‚æœå•Ÿç”¨ MLLMï¼Œå…ˆæª¢æŸ¥æœå‹™æ˜¯å¦å¯ç”¨
    if use_mllm and use_llm:
        logger.info("æª¢æŸ¥ MLLM æœå‹™å¥åº·ç‹€æ…‹...")
        mllm_healthy = await check_mllm_health()
        if not mllm_healthy:
            logger.warning("MLLM æœå‹™ä¸å¯ç”¨ï¼Œå°‡é€€å›ä½¿ç”¨æ¨™æº– LLM")
            use_mllm = False
    # åŸ·è¡Œè¦–è¦ºé æ¸¬
    visual_predict_res = pipeline.visual_predict(
        input=file_path,
        use_doc_orientation_classify=use_doc_orientation_classify,
        use_doc_unwarping=use_doc_unwarping,
        use_textline_orientation=use_textline_orientation,
        use_common_ocr=True,
        use_seal_recognition=use_seal_recognition,
        use_table_recognition=use_table_recognition,
    )

    visual_info_list = []
    output_images = []
    for res in visual_predict_res:
        visual_info_list.append(res["visual_info"])
        layout_parsing_result = res["layout_parsing_result"]
        # åŸ·è¡Œä¿å­˜æ“ä½œ
        layout_parsing_result.save_to_img(task_output_dir)

        # ç²å–ä¿å­˜å¾Œçš„æª”æ¡ˆåˆ—è¡¨
        files = set(os.listdir(task_output_dir)) if os.path.exists(task_output_dir) else set()

        for file in files:
            if file.endswith('.png'):
                output_images.append(file)

    

    # åŸ·è¡ŒèŠå¤©æŸ¥è©¢
    chat_result = {}
    if use_llm:
        if use_mllm:
            logger.info("ä½¿ç”¨ MLLM é€²è¡Œå¤šæ¨¡æ…‹é æ¸¬...")
            try:
                mllm_predict_res = pipeline.mllm_pred(
                    input=file_path,
                    key_list=key_list_parsed,
                )
                mllm_predict_info = mllm_predict_res["mllm_res"]
                logger.info("MLLM é æ¸¬å®Œæˆï¼Œæ•´åˆåˆ°èŠå¤©çµæœ...")
            
                chat_result = pipeline.chat(
                    key_list=key_list_parsed,
                    visual_info=visual_info_list,
                    mllm_predict_info=mllm_predict_info,
                )
                logger.info("MLLM æ•´åˆèŠå¤©å®Œæˆ")
            except Exception as e:
                logger.error(f"MLLM è™•ç†å¤±æ•—: {str(e)}ï¼Œé€€å›æ¨™æº– LLM")
                chat_result = pipeline.chat(
                    key_list=key_list_parsed,
                    visual_info=visual_info_list,
                )
        else:
            logger.info("ä½¿ç”¨æ¨™æº– LLM é€²è¡Œé—œéµå­—æå–...")
            chat_result = pipeline.chat(
                key_list=key_list_parsed,
                visual_info=visual_info_list,
            )
            logger.info("æ¨™æº– LLM æå–å®Œæˆ")

    # çµ„åˆå›æ‡‰è³‡æ–™
    response_data = {
        "chat_result": chat_result.get("chat_res") if use_llm else None,
        "visual_info_list": visual_info_list,
        "key_list": key_list_parsed,
        "output_images": output_images,
        "original_filename": original_filename,
        "settings": {
            "use_doc_orientation_classify": use_doc_orientation_classify,
            "use_doc_unwarping": use_doc_unwarping,
            "use_textline_orientation": use_textline_orientation,
            "use_seal_recognition": use_seal_recognition,
            "use_table_recognition": use_table_recognition,
            "use_llm": use_llm,
            "use_mllm": use_mllm
        }
    }

    return response_data

@app.get("/", response_class=HTMLResponse)
async def index(request: Request):
    """è¿”å›ä¸Šå‚³é é¢"""
    return templates.TemplateResponse("index.html", {"request": request})

@app.post("/ocr", response_model=OCRResponse)
async def process_ocr(
    file: UploadFile = File(...),
    key_list: str = Form(...),
    use_doc_orientation_classify: bool = Form(False),
    use_doc_unwarping: bool = Form(False),
    use_textline_orientation: bool = Form(False),
    use_seal_recognition: bool = Form(False),
    use_table_recognition: bool = Form(True),
    use_llm: bool = Form(True),
    use_mllm: bool = Form(False),
):
    """è™•ç†åœ–ç‰‡ OCR è«‹æ±‚"""
    temp_file_path = None
    task_id = str(uuid.uuid4())
    task_output_dir = os.path.join(output_dir, task_id)

    logger.info(f"æ”¶åˆ° OCR è«‹æ±‚ - ä»»å‹™ID: {task_id}, æª”æ¡ˆåç¨±: {file.filename}, æª”æ¡ˆé¡å‹: {file.content_type}")

    try:
        # æª¢æŸ¥æª”æ¡ˆé¡å‹
        if not (file.content_type.startswith('image/') or file.content_type == 'application/pdf'):
            logger.warning(f"ç„¡æ•ˆçš„æª”æ¡ˆé¡å‹: {file.content_type} - ä»»å‹™ID: {task_id}")
            raise HTTPException(status_code=400, detail="è«‹ä¸Šå‚³æœ‰æ•ˆçš„åœ–ç‰‡æª”æ¡ˆæˆ–PDFæª”æ¡ˆ")

        # è§£æé—œéµå­—åˆ—è¡¨
        try:
            key_list_parsed = json.loads(key_list)
            logger.info(f"è§£æé—œéµå­—åˆ—è¡¨æˆåŠŸ - ä»»å‹™ID: {task_id}, é—œéµå­—æ•¸é‡: {len(key_list_parsed)}")
        except json.JSONDecodeError as e:
            logger.error(f"é—œéµå­—åˆ—è¡¨è§£æå¤±æ•— - ä»»å‹™ID: {task_id}, éŒ¯èª¤: {str(e)}")
            raise HTTPException(status_code=400, detail="é—œéµå­—åˆ—è¡¨æ ¼å¼éŒ¯èª¤")

        # å‰µå»ºä»»å‹™å°ˆå±¬è¼¸å‡ºç›®éŒ„
        os.makedirs(task_output_dir, exist_ok=True)
        logger.debug(f"å‰µå»ºè¼¸å‡ºç›®éŒ„ - ä»»å‹™ID: {task_id}, è·¯å¾‘: {task_output_dir}")

        # å‰µå»ºè‡¨æ™‚æª”æ¡ˆ
        with tempfile.NamedTemporaryFile(delete=False, suffix=os.path.splitext(file.filename)[1]) as temp_file:
            content = await file.read()
            temp_file.write(content)
            temp_file_path = temp_file.name

        logger.info(f"é–‹å§‹ OCR è™•ç† - ä»»å‹™ID: {task_id}, æª”æ¡ˆå¤§å°: {len(content)} bytes")

        # èª¿ç”¨æ ¸å¿ƒ OCR è™•ç†å‡½æ•¸
        response_data = await perform_ocr_on_file(
            file_path=temp_file_path,
            key_list_parsed=key_list_parsed,
            original_filename=file.filename,
            task_output_dir=task_output_dir,
            use_doc_orientation_classify=use_doc_orientation_classify,
            use_doc_unwarping=use_doc_unwarping,
            use_textline_orientation=use_textline_orientation,
            use_seal_recognition=use_seal_recognition,
            use_table_recognition=use_table_recognition,
            use_llm=use_llm,
            use_mllm=use_mllm
        )

        # ä¿å­˜ response_data åˆ° JSON æª”æ¡ˆ
        response_file = os.path.join(task_output_dir, "response.json")
        with open(response_file, 'w', encoding='utf-8') as f:
            json.dump(response_data, f, ensure_ascii=False, indent=2)

        # æ·»åŠ  task_id åˆ°å›æ‡‰
        response_data["task_id"] = task_id

        # æ›´æ–°è¼¸å‡ºåœ–ç‰‡è·¯å¾‘ç‚ºç›¸å°æ–¼ output çš„è·¯å¾‘
        response_data["output_images"] = [f"{task_id}/{img}" for img in response_data["output_images"]]

        # å„²å­˜ä»»å‹™è³‡è¨Šåˆ°è³‡æ–™åº«
        database.insert_task(
            task_id=task_id,
            original_filename=file.filename,
            output_directory=task_output_dir,
            response_file=response_file,
            file_type='pdf' if file.content_type == 'application/pdf' else 'image',
            matched_page_number=None,
            settings=response_data["settings"]
        )

        logger.info(f"OCR è™•ç†å®Œæˆ - ä»»å‹™ID: {task_id}, æª”æ¡ˆåç¨±: {file.filename}, è¼¸å‡ºåœ–ç‰‡æ•¸é‡: {len(response_data['output_images'])}")
        return OCRResponse(success=True, data=response_data)

    except HTTPException as he:
        logger.warning(f"HTTPç•°å¸¸ - ä»»å‹™ID: {task_id}, ç‹€æ…‹ç¢¼: {he.status_code}, è©³æƒ…: {he.detail}")
        raise
    except Exception as e:
        # å¦‚æœç™¼ç”ŸéŒ¯èª¤ï¼Œæ¸…ç†è¼¸å‡ºç›®éŒ„
        logger.error(f"OCR è™•ç†å¤±æ•— - ä»»å‹™ID: {task_id}, éŒ¯èª¤: {str(e)}", exc_info=True)
        if os.path.exists(task_output_dir):
            shutil.rmtree(task_output_dir)
        return OCRResponse(success=False, error=f"è™•ç†éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
    finally:
        # æ¸…ç†è‡¨æ™‚æª”æ¡ˆ
        if temp_file_path and os.path.exists(temp_file_path):
            os.unlink(temp_file_path)
            logger.debug(f"æ¸…ç†è‡¨æ™‚æª”æ¡ˆ - ä»»å‹™ID: {task_id}")

@app.post("/ocr-with-matching", response_model=OCRResponse)
async def process_ocr_with_matching(
    pdf_file: UploadFile = File(...),
    positive_templates: List[UploadFile] = File(...),
    negative_templates: List[UploadFile] = File(default=[]),
    key_list: str = Form(...),
    use_doc_orientation_classify: bool = Form(False),
    use_doc_unwarping: bool = Form(False),
    use_textline_orientation: bool = Form(False),
    use_seal_recognition: bool = Form(False),
    use_table_recognition: bool = Form(True),
    use_llm: bool = Form(True),
    positive_threshold: float = Form(0.25),
    negative_threshold: float = Form(0.30),
    skip_voided: bool = Form(False),
    top_n_for_void_check: int = Form(5),
    use_mllm: bool = Form(False),
):
    """
    è™•ç† PDF é é¢åŒ¹é…å’Œ OCR è«‹æ±‚
    1. æ¥å— PDF æ–‡ä»¶ã€æ­£ä¾‹ç¯„æœ¬åœ–ç‰‡ã€åä¾‹ç¯„æœ¬åœ–ç‰‡
    2. èª¿ç”¨ CLIP æœå‹™æ‰¾å‡ºæœ€ç›¸ä¼¼çš„é é¢
    3. å°è©²é é¢åŸ·è¡Œ OCR è™•ç†
    """
    temp_pdf_path = None
    task_id = str(uuid.uuid4())
    task_output_dir = os.path.join(output_dir, task_id)

    try:
        # æª¢æŸ¥ PDF æª”æ¡ˆé¡å‹
        if pdf_file.content_type != 'application/pdf':
            raise HTTPException(status_code=400, detail="è«‹ä¸Šå‚³æœ‰æ•ˆçš„ PDF æª”æ¡ˆ")

        # è§£æé—œéµå­—åˆ—è¡¨
        try:
            key_list_parsed = json.loads(key_list)
        except json.JSONDecodeError:
            raise HTTPException(status_code=400, detail="é—œéµå­—åˆ—è¡¨æ ¼å¼éŒ¯èª¤")

        # å‰µå»ºä»»å‹™å°ˆå±¬è¼¸å‡ºç›®éŒ„
        os.makedirs(task_output_dir, exist_ok=True)

        # ä¿å­˜ PDF åˆ°è‡¨æ™‚æª”æ¡ˆ
        with tempfile.NamedTemporaryFile(delete=False, suffix='.pdf') as temp_pdf:
            content = await pdf_file.read()
            temp_pdf.write(content)
            temp_pdf_path = temp_pdf.name

        # èª¿ç”¨ CLIP æœå‹™é€²è¡Œé é¢åŒ¹é…
        print(f"èª¿ç”¨ CLIP æœå‹™é€²è¡Œé é¢åŒ¹é…...")
        best_page_number, best_page_image, best_score, all_scores, voided_pages = await call_clip_service(
            temp_pdf_path,
            positive_templates,
            negative_templates,
            positive_threshold,
            negative_threshold,
            skip_voided,
            top_n_for_void_check
        )

        if best_page_number is None:
            # æ¸…ç†è¼¸å‡ºç›®éŒ„
            if os.path.exists(task_output_dir):
                shutil.rmtree(task_output_dir)
            return OCRResponse(
                success=False,
                error=f"æœªæ‰¾åˆ°ç¬¦åˆæ¢ä»¶çš„é é¢ã€‚è«‹èª¿æ•´é–¾å€¼åƒæ•¸ã€‚æ‰€æœ‰é é¢åˆ†æ•¸: {all_scores}"
            )

        print(f"æ‰¾åˆ°æœ€ä½³åŒ¹é…é é¢: ç¬¬ {best_page_number} é , åˆ†æ•¸: {best_score:.4f}")

        # å°‡åŒ¹é…çš„é é¢ä¿å­˜åˆ°ä»»å‹™è¼¸å‡ºç›®éŒ„
        matched_page_filename = f"matched_page_{best_page_number}.png"
        matched_page_path = os.path.join(task_output_dir, matched_page_filename)
        best_page_image.save(matched_page_path, 'PNG')

        # èª¿ç”¨æ ¸å¿ƒ OCR è™•ç†å‡½æ•¸
        ocr_response_data = await perform_ocr_on_file(
            file_path=matched_page_path,
            key_list_parsed=key_list_parsed,
            original_filename=pdf_file.filename,
            task_output_dir=task_output_dir,
            use_doc_orientation_classify=use_doc_orientation_classify,
            use_doc_unwarping=use_doc_unwarping,
            use_textline_orientation=use_textline_orientation,
            use_seal_recognition=use_seal_recognition,
            use_table_recognition=use_table_recognition,
            use_llm=use_llm,
            use_mllm=use_mllm
        )

        # åœ¨ OCR çµæœä¸­æ·»åŠ é é¢åŒ¹é…è³‡è¨Š
        response_data = {
            **ocr_response_data,  # åŒ…å«æ‰€æœ‰ OCR çµæœ
            "matched_page_number": best_page_number,
            "matching_score": float(best_score),
            "all_page_scores": all_scores,
            "matched_page_path": f"{task_id}/{matched_page_filename}",
        }

        # å¦‚æœæœ‰è·³éçš„å»¢æ­¢é é¢ï¼Œæ·»åŠ åˆ°çµæœä¸­
        if voided_pages:
            response_data["voided_pages_checked"] = voided_pages

        # æ›´æ–° settings ä»¥åŒ…å«åŒ¹é…é–¾å€¼
        response_data["settings"]["positive_threshold"] = positive_threshold
        response_data["settings"]["negative_threshold"] = negative_threshold
        response_data["settings"]["skip_voided"] = skip_voided
        response_data["settings"]["top_n_for_void_check"] = top_n_for_void_check

        # ä¿å­˜ response_data åˆ° JSON æª”æ¡ˆ
        response_file = os.path.join(task_output_dir, "response.json")
        with open(response_file, 'w', encoding='utf-8') as f:
            json.dump(response_data, f, ensure_ascii=False, indent=2)

        # æ·»åŠ  task_id åˆ°å›æ‡‰
        response_data["task_id"] = task_id

        # æ›´æ–°è¼¸å‡ºåœ–ç‰‡è·¯å¾‘ç‚ºç›¸å°æ–¼ output çš„è·¯å¾‘
        response_data["output_images"] = [f"{task_id}/{img}" for img in response_data["output_images"]]

        # å„²å­˜ä»»å‹™è³‡è¨Šåˆ°è³‡æ–™åº«
        database.insert_task(
            task_id=task_id,
            original_filename=pdf_file.filename,
            output_directory=task_output_dir,
            response_file=response_file,
            file_type='pdf',
            matched_page_number=best_page_number,
            settings=response_data["settings"]
        )

        return OCRResponse(success=True, data=response_data)

    except HTTPException:
        raise
    except Exception as e:
        import traceback
        error_detail = f"è™•ç†éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {str(e)}\n{traceback.format_exc()}"
        print(error_detail)
        # å¦‚æœç™¼ç”ŸéŒ¯èª¤ï¼Œæ¸…ç†è¼¸å‡ºç›®éŒ„
        if os.path.exists(task_output_dir):
            shutil.rmtree(task_output_dir)
        return OCRResponse(success=False, error=error_detail)

    finally:
        # æ¸…ç†è‡¨æ™‚æª”æ¡ˆ
        if temp_pdf_path and os.path.exists(temp_pdf_path):
            try:
                os.unlink(temp_pdf_path)
            except Exception as e:
                print(f"æ¸…ç†è‡¨æ™‚æª”æ¡ˆå¤±æ•—: {temp_pdf_path}, éŒ¯èª¤: {e}")

@app.get("/admin", response_class=HTMLResponse)
async def admin_page(request: Request):
    """è¿”å›ç®¡ç†å¾Œå°é é¢"""
    return templates.TemplateResponse("admin.html", {"request": request})

@app.get("/admin/tasks")
async def get_all_tasks(include_deleted: bool = False):
    """å–å¾—æ‰€æœ‰ä»»å‹™åˆ—è¡¨"""
    try:
        tasks = database.get_all_tasks(include_deleted=include_deleted)
        return {"success": True, "tasks": tasks}
    except Exception as e:
        return {"success": False, "error": str(e)}

@app.get("/admin/task/{task_id}", response_class=HTMLResponse)
async def view_task_detail(request: Request, task_id: str):
    """æŸ¥çœ‹ä»»å‹™è©³æƒ…é é¢"""
    task = database.get_task_by_id(task_id)
    if not task:
        raise HTTPException(status_code=404, detail="ä»»å‹™ä¸å­˜åœ¨")

    # è®€å– response.json
    response_data = None
    if os.path.exists(task['response_file']):
        with open(task['response_file'], 'r', encoding='utf-8') as f:
            response_data = json.load(f)

    return templates.TemplateResponse("task_detail.html", {
        "request": request,
        "task": task,
        "response_data": response_data
    })

@app.delete("/admin/task/{task_id}")
async def delete_task(task_id: str):
    """åˆªé™¤ä»»å‹™"""
    try:
        # å–å¾—ä»»å‹™è³‡è¨Š
        task = database.get_task_by_id(task_id)
        if not task:
            return {"success": False, "error": "ä»»å‹™ä¸å­˜åœ¨"}

        if task['is_deleted']:
            return {"success": False, "error": "ä»»å‹™å·²è¢«åˆªé™¤"}

        # åˆªé™¤å¯¦é«”æª”æ¡ˆ
        if os.path.exists(task['output_directory']):
            shutil.rmtree(task['output_directory'])

        # æ¨™è¨˜è³‡æ–™åº«ç‚ºå·²åˆªé™¤
        database.mark_task_deleted(task_id)

        return {"success": True, "message": "ä»»å‹™å·²åˆªé™¤"}
    except Exception as e:
        return {"success": False, "error": str(e)}

# ==================== æ‰¹æ¬¡ä»»å‹™ç®¡ç† API ====================

@app.get("/batch-tasks", response_class=HTMLResponse)
async def batch_tasks_page(request: Request):
    """æ‰¹æ¬¡ä»»å‹™ç®¡ç†é é¢"""
    return templates.TemplateResponse("batch_tasks.html", {"request": request})

@app.get("/batch-tasks/{task_id}/detail", response_class=HTMLResponse)
async def batch_task_detail_page(request: Request, task_id: str):
    """æ‰¹æ¬¡ä»»å‹™è©³æƒ…é é¢"""
    try:
        task = batch_db.get_task_by_id(task_id)
        if not task:
            raise HTTPException(status_code=404, detail="ä»»å‹™ä¸å­˜åœ¨")

        statistics = batch_db.get_task_statistics(task_id)
        keywords = batch_db.get_task_keywords(task_id)

        return templates.TemplateResponse("batch_task_detail.html", {
            "request": request,
            "task": task,
            "statistics": statistics,
            "keywords": keywords
        })
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/batch-tasks/create")
async def create_batch_task(
    task_name: str = Form(...),
    source_path: str = Form(...)
):
    """å‰µå»ºæ–°çš„æ‰¹æ¬¡ä»»å‹™ä¸¦æƒææª”æ¡ˆ"""
    logger.info(f"æ”¶åˆ°æ‰¹æ¬¡ä»»å‹™å‰µå»ºè«‹æ±‚ - ä»»å‹™åç¨±: {task_name}, ä¾†æºè·¯å¾‘: {source_path}")

    try:
        # é©—è­‰è·¯å¾‘
        if not os.path.exists(source_path):
            logger.warning(f"æ‰¹æ¬¡ä»»å‹™å‰µå»ºå¤±æ•— - è·¯å¾‘ä¸å­˜åœ¨: {source_path}")
            return {"success": False, "error": "æŒ‡å®šçš„è·¯å¾‘ä¸å­˜åœ¨"}

        if not os.path.isdir(source_path):
            logger.warning(f"æ‰¹æ¬¡ä»»å‹™å‰µå»ºå¤±æ•— - è·¯å¾‘ä¸æ˜¯ç›®éŒ„: {source_path}")
            return {"success": False, "error": "æŒ‡å®šçš„è·¯å¾‘ä¸æ˜¯ç›®éŒ„"}

        # å‰µå»ºä»»å‹™
        task_id = str(uuid.uuid4())
        batch_db.create_batch_task(task_id, task_name, source_path)
        logger.info(f"æ‰¹æ¬¡ä»»å‹™å·²å‰µå»º - ä»»å‹™ID: {task_id}, ä»»å‹™åç¨±: {task_name}")

        # æƒææª”æ¡ˆ
        files = batch_processor.scan_directory(source_path)
        logger.info(f"æƒæç›®éŒ„å®Œæˆ - ä»»å‹™ID: {task_id}, æ‰¾åˆ° {len(files)} å€‹ PDF æª”æ¡ˆ")

        if not files:
            logger.warning(f"æ‰¹æ¬¡ä»»å‹™å‰µå»ºå¤±æ•— - æœªæ‰¾åˆ° PDF æª”æ¡ˆ, ä»»å‹™ID: {task_id}")
            return {"success": False, "error": "æœªæ‰¾åˆ°ä»»ä½• PDF æª”æ¡ˆ"}

        # æ·»åŠ æª”æ¡ˆåˆ°ä»»å‹™
        batch_db.add_files_to_task(task_id, files)
        logger.info(f"æ‰¹æ¬¡ä»»å‹™å‰µå»ºæˆåŠŸ - ä»»å‹™ID: {task_id}, æª”æ¡ˆæ•¸é‡: {len(files)}")

        return {
            "success": True,
            "task_id": task_id,
            "total_files": len(files),
            "message": f"æˆåŠŸå‰µå»ºä»»å‹™ï¼Œæ‰¾åˆ° {len(files)} å€‹ PDF æª”æ¡ˆ"
        }

    except Exception as e:
        import traceback
        logger.error(f"æ‰¹æ¬¡ä»»å‹™å‰µå»ºå¤±æ•— - ä»»å‹™åç¨±: {task_name}, éŒ¯èª¤: {str(e)}", exc_info=True)
        return {"success": False, "error": f"å‰µå»ºä»»å‹™å¤±æ•—: {str(e)}\n{traceback.format_exc()}"}

@app.get("/api/batch-tasks")
async def get_batch_tasks(include_deleted: bool = False):
    """å–å¾—æ‰€æœ‰æ‰¹æ¬¡ä»»å‹™"""
    try:
        tasks = batch_db.get_all_tasks(include_deleted=include_deleted)
        return {"success": True, "tasks": tasks}
    except Exception as e:
        return {"success": False, "error": str(e)}

@app.get("/api/batch-tasks/{task_id}")
async def get_batch_task_detail(task_id: str):
    """å–å¾—æ‰¹æ¬¡ä»»å‹™è©³æƒ…"""
    try:
        task = batch_db.get_task_by_id(task_id)
        if not task:
            return {"success": False, "error": "ä»»å‹™ä¸å­˜åœ¨"}

        # å–å¾—çµ±è¨ˆè³‡è¨Š
        stats = batch_db.get_task_statistics(task_id)

        # å–å¾—é—œéµå­—
        keywords = batch_db.get_task_keywords(task_id)

        return {
            "success": True,
            "task": task,
            "statistics": stats,
            "keywords": keywords
        }
    except Exception as e:
        return {"success": False, "error": str(e)}

@app.get("/api/batch-tasks/{task_id}/keywords")
async def get_batch_task_keywords(task_id: str):
    """å–å¾—æ‰¹æ¬¡ä»»å‹™çš„é—œéµå­—"""
    try:
        keywords = batch_db.get_task_keywords(task_id)
        return {"success": True, "keywords": keywords}
    except Exception as e:
        return {"success": False, "error": str(e)}

@app.get("/api/batch-tasks/{task_id}/files")
async def get_batch_task_files(
    task_id: str,
    status: Optional[str] = None,
    stage1_status: Optional[str] = None,
    stage2_status: Optional[str] = None,
    limit: int = 50,
    offset: int = 0,
    exclude_base64: bool = True
):
    """
    å–å¾—ä»»å‹™çš„æª”æ¡ˆåˆ—è¡¨

    Args:
        task_id: ä»»å‹™ID
        status: ç‹€æ…‹ç¯©é¸
        stage1_status: ç¬¬ä¸€éšæ®µç‹€æ…‹ç¯©é¸
        stage2_status: ç¬¬äºŒéšæ®µç‹€æ…‹ç¯©é¸
        limit: æ¯é æ•¸é‡(é è¨­50,æœ€å¤§500)
        offset: åç§»é‡
        exclude_base64: æ˜¯å¦æ’é™¤Base64åœ–ç‰‡è³‡æ–™(é è¨­True)
    """
    try:
        # é™åˆ¶æœ€å¤§æ¯é æ•¸é‡,é¿å…è¨˜æ†¶é«”éè¼‰
        limit = min(limit, 500)

        # å–å¾—æª”æ¡ˆåˆ—è¡¨(ä¸åŒ…å«Base64ä»¥ç¯€çœè¨˜æ†¶é«”)
        files = batch_db.get_task_files(
            task_id,
            status=status,
            stage1_status=stage1_status,
            stage2_status=stage2_status,
            limit=limit,
            offset=offset,
            exclude_base64=exclude_base64
        )

        # å–å¾—ç¬¦åˆæ¢ä»¶çš„ç¸½æ•¸é‡
        total_count = batch_db.get_task_files_count(
            task_id,
            status=status,
            stage1_status=stage1_status,
            stage2_status=stage2_status
        )

        return {
            "success": True,
            "files": files,
            "pagination": {
                "total": total_count,
                "limit": limit,
                "offset": offset,
                "has_more": (offset + limit) < total_count
            }
        }
    except Exception as e:
        return {"success": False, "error": str(e)}

@app.post("/api/batch-tasks/{task_id}/stage1/config")
async def configure_stage1(
    task_id: str,
    positive_templates: List[UploadFile] = File(...),
    negative_templates: List[UploadFile] = File(default=[]),
    positive_threshold: float = Form(0.25),
    negative_threshold: float = Form(0.30),
    skip_voided: bool = Form(False),
    top_n_for_void_check: int = Form(5)
):
    """é…ç½®ç¬¬ä¸€éšæ®µåƒæ•¸"""
    try:
        # å°‡ç¯„æœ¬åœ–ç‰‡è½‰æ›ç‚º Base64
        positive_b64_list = []
        for template in positive_templates:
            content = await template.read()
            b64_str = base64.b64encode(content).decode('utf-8')
            positive_b64_list.append(b64_str)

        negative_b64_list = []
        for template in negative_templates:
            content = await template.read()
            b64_str = base64.b64encode(content).decode('utf-8')
            negative_b64_list.append(b64_str)

        # ä¿å­˜é…ç½®
        config = {
            'positive_templates': positive_b64_list,
            'negative_templates': negative_b64_list,
            'positive_threshold': positive_threshold,
            'negative_threshold': negative_threshold,
            'skip_voided': skip_voided,
            'top_n_for_void_check': top_n_for_void_check
        }

        batch_db.save_task_stage1_config(task_id, config)

        return {"success": True, "message": "ç¬¬ä¸€éšæ®µé…ç½®å·²ä¿å­˜"}

    except Exception as e:
        import traceback
        return {"success": False, "error": f"é…ç½®å¤±æ•—: {str(e)}\n{traceback.format_exc()}"}

@app.post("/api/batch-tasks/{task_id}/stage2/config")
async def configure_stage2(
    task_id: str,
    keywords: str = Form(...),
    use_doc_orientation_classify: bool = Form(False),
    use_doc_unwarping: bool = Form(False),
    use_textline_orientation: bool = Form(False),
    use_seal_recognition: bool = Form(False),
    use_table_recognition: bool = Form(True),
    use_llm: bool = Form(True),
    use_mllm: bool = Form(False),
):
    """é…ç½®ç¬¬äºŒéšæ®µåƒæ•¸"""
    try:
        # è§£æé—œéµå­—
        keywords_list = json.loads(keywords)

        # ä¿å­˜é…ç½®
        config = {
            'use_doc_orientation_classify': use_doc_orientation_classify,
            'use_doc_unwarping': use_doc_unwarping,
            'use_textline_orientation': use_textline_orientation,
            'use_seal_recognition': use_seal_recognition,
            'use_table_recognition': use_table_recognition,
            'use_llm': use_llm,
            'use_mllm': use_mllm
        }

        batch_db.save_task_stage2_config(task_id, config, keywords_list)

        return {"success": True, "message": "ç¬¬äºŒéšæ®µé…ç½®å·²ä¿å­˜"}

    except Exception as e:
        import traceback
        return {"success": False, "error": f"é…ç½®å¤±æ•—: {str(e)}\n{traceback.format_exc()}"}

@app.post("/api/batch-tasks/{task_id}/stage1/start")
async def start_stage1_processing(task_id: str):
    """é–‹å§‹ç¬¬ä¸€éšæ®µè™•ç†"""
    try:
        batch_processor.start_task_stage1(task_id, CLIP_SERVICE_URL)
        return {"success": True, "message": "ç¬¬ä¸€éšæ®µè™•ç†å·²å•Ÿå‹•"}
    except Exception as e:
        return {"success": False, "error": str(e)}

@app.post("/api/batch-tasks/{task_id}/stage2/start")
async def start_stage2_processing(task_id: str):
    """é–‹å§‹ç¬¬äºŒéšæ®µè™•ç†"""
    try:
        batch_processor.start_task_stage2(task_id)
        return {"success": True, "message": "ç¬¬äºŒéšæ®µè™•ç†å·²å•Ÿå‹•"}
    except Exception as e:
        return {"success": False, "error": str(e)}

@app.post("/api/batch-tasks/{task_id}/pause")
async def pause_task_processing(task_id: str):
    """æš«åœä»»å‹™"""
    try:
        batch_processor.pause_task(task_id)
        return {"success": True, "message": "ä»»å‹™å·²æš«åœ"}
    except Exception as e:
        return {"success": False, "error": str(e)}

@app.post("/api/batch-tasks/{task_id}/stop")
async def stop_task_processing(task_id: str):
    """åœæ­¢ä»»å‹™"""
    try:
        batch_processor.stop_task(task_id)
        return {"success": True, "message": "ä»»å‹™å·²åœæ­¢"}
    except Exception as e:
        return {"success": False, "error": str(e)}

@app.post("/api/batch-tasks/{task_id}/stage1/restart")
async def restart_stage1_processing(task_id: str):
    """é‡æ–°é–‹å§‹ç¬¬ä¸€éšæ®µ"""
    try:
        batch_processor.restart_task_stage1(task_id, CLIP_SERVICE_URL)
        return {"success": True, "message": "ç¬¬ä¸€éšæ®µå·²é‡æ–°å•Ÿå‹•"}
    except Exception as e:
        return {"success": False, "error": str(e)}

@app.post("/api/batch-tasks/{task_id}/stage2/restart")
async def restart_stage2_processing(task_id: str):
    """é‡æ–°é–‹å§‹ç¬¬äºŒéšæ®µ"""
    try:
        batch_processor.restart_task_stage2(task_id)
        return {"success": True, "message": "ç¬¬äºŒéšæ®µå·²é‡æ–°å•Ÿå‹•"}
    except Exception as e:
        return {"success": False, "error": str(e)}

@app.post("/api/batch-tasks/{task_id}/resume")
async def resume_failed_task(task_id: str):
    """
    å¾å¤±æ•—é»ç¹¼çºŒåŸ·è¡Œä»»å‹™

    æ­¤ç«¯é»é©ç”¨æ–¼ä»»å‹™ä¸­é€”å¤±æ•—çš„æƒ…æ³,ä¾‹å¦‚:
    - åŸ·è¡Œåˆ° 1200/3000 æ™‚å› éŒ¯èª¤ä¸­æ–·
    - ä»»å‹™ç‹€æ…‹è®Šç‚º 'failed'
    - èª¿ç”¨æ­¤ç«¯é»å¾Œ,å¾ç¬¬ 1201 å€‹æª”æ¡ˆç¹¼çºŒåŸ·è¡Œ
    - å·²å®Œæˆå’Œå·²å¤±æ•—çš„æª”æ¡ˆä¸æœƒé‡æ–°è™•ç†
    """
    try:
        batch_processor.resume_task_from_failure(task_id, CLIP_SERVICE_URL)

        # å–å¾—ä»»å‹™è³‡è¨Šä»¥è¿”å›è©³ç´°ä¿¡æ¯
        task = batch_db.get_task_by_id(task_id)
        stats = batch_db.get_task_statistics(task_id)

        stage = task['stage']
        if stage == 1:
            pending = stats.get('stage1_pending', 0)
            completed = stats.get('stage1_completed', 0)
            message = f"ä»»å‹™å·²å¾ç¬¬ä¸€éšæ®µç¹¼çºŒåŸ·è¡Œã€‚å·²å®Œæˆ: {completed}, å¾…è™•ç†: {pending}"
        else:
            pending = stats.get('stage2_pending', 0)
            completed = stats.get('stage2_completed', 0)
            message = f"ä»»å‹™å·²å¾ç¬¬äºŒéšæ®µç¹¼çºŒåŸ·è¡Œã€‚å·²å®Œæˆ: {completed}, å¾…è™•ç†: {pending}"

        return {
            "success": True,
            "message": message,
            "stage": stage,
            "statistics": stats
        }
    except Exception as e:
        import traceback
        return {
            "success": False,
            "error": str(e),
            "traceback": traceback.format_exc()
        }

@app.delete("/api/batch-tasks/{task_id}")
async def delete_batch_task(task_id: str):
    """åˆªé™¤æ‰¹æ¬¡ä»»å‹™"""
    try:
        batch_db.mark_task_deleted(task_id)
        return {"success": True, "message": "ä»»å‹™å·²åˆªé™¤"}
    except Exception as e:
        return {"success": False, "error": str(e)}

@app.get("/api/batch-tasks/{task_id}/files/{file_id}")
async def get_file_detail(task_id: str, file_id: int):
    """å–å¾—å–®å€‹æª”æ¡ˆçš„è©³ç´°è³‡è¨Šï¼ˆåŒ…å«åœ–ç‰‡ï¼‰"""
    try:
        conn = batch_db.get_connection()
        cursor = conn.cursor()

        cursor.execute('''
            SELECT * FROM batch_files
            WHERE id = ? AND task_id = ?
        ''', (file_id, task_id))

        row = cursor.fetchone()
        if not row:
            return {"success": False, "error": "æª”æ¡ˆä¸å­˜åœ¨"}

        file_info = dict(row)

        # è§£æ JSON è³‡æ–™
        if file_info['ocr_result']:
            try:
                file_info['ocr_result'] = json.loads(file_info['ocr_result'])
            except (json.JSONDecodeError, TypeError, ValueError):  # nosec B110
                # å¦‚æœç„¡æ³•è§£æ JSONï¼Œä¿æŒåŸå§‹å­—ç¬¦ä¸²å€¼
                pass

        if file_info['extracted_keywords']:
            try:
                file_info['extracted_keywords'] = json.loads(file_info['extracted_keywords'])
            except (json.JSONDecodeError, TypeError, ValueError):  # nosec B110
                # å¦‚æœç„¡æ³•è§£æ JSONï¼Œä¿æŒåŸå§‹å­—ç¬¦ä¸²å€¼
                pass

        return {"success": True, "file": file_info}

    except Exception as e:
        return {"success": False, "error": str(e)}

@app.get("/api/batch-tasks/{task_id}/files/{file_id}/image")
async def get_file_matched_image(task_id: str, file_id: int):
    """å–å¾—æª”æ¡ˆçš„åŒ¹é…é é¢åœ–ç‰‡"""
    try:
        from fastapi.responses import Response

        conn = batch_db.get_connection()
        cursor = conn.cursor()

        cursor.execute('''
            SELECT matched_page_base64 FROM batch_files
            WHERE id = ? AND task_id = ?
        ''', (file_id, task_id))

        row = cursor.fetchone()
        if not row or not row['matched_page_base64']:
            return {"success": False, "error": "åœ–ç‰‡ä¸å­˜åœ¨"}

        # è§£ç¢¼ Base64
        img_data = base64.b64decode(row['matched_page_base64'])

        return Response(
            content=img_data,
            media_type="image/png",
            headers={"Content-Disposition": f"inline; filename=page_{file_id}.png"}
        )

    except Exception as e:
        return {"success": False, "error": str(e)}

@app.get("/api/batch-tasks/{task_id}/files/{file_id}/pdf")
async def get_file_original_pdf(task_id: str, file_id: int):
    """å–å¾—æª”æ¡ˆçš„åŸå§‹ PDF"""
    try:
        from fastapi.responses import FileResponse
        import os

        conn = batch_db.get_connection()
        cursor = conn.cursor()

        cursor.execute('''
            SELECT file_path, file_name FROM batch_files
            WHERE id = ? AND task_id = ?
        ''', (file_id, task_id))

        row = cursor.fetchone()
        if not row or not row['file_path']:
            raise HTTPException(status_code=404, detail="æª”æ¡ˆä¸å­˜åœ¨")

        file_path = row['file_path']
        file_name = row['file_name']

        # è¿”å›æ–‡ä»¶ - ä½¿ç”¨URLç·¨ç¢¼è™•ç†ä¸­æ–‡æª”å
        
        encoded_filename = quote(file_name)

        headers = {
            'Content-Disposition': f'inline; filename*=UTF-8\'\'{encoded_filename}'
        }

        return FileResponse(
            path=file_path,
            media_type="application/pdf",
            headers=headers
        )

    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/batch-tasks/{task_id}/preview")
async def get_task_preview(task_id: str, limit: int = 10):
    """å–å¾—ä»»å‹™çš„é è¦½è³‡è¨Šï¼ˆåŒ…å«éƒ¨åˆ†æª”æ¡ˆçš„ç¸®åœ–ï¼‰"""
    try:
        # å–å¾—å·²å®Œæˆç¬¬ä¸€éšæ®µçš„æª”æ¡ˆ
        files = batch_db.get_task_files(
            task_id,
            stage1_status='completed',
            limit=limit
        )

        preview_data = []
        for f in files:
            preview_data.append({
                'id': f['id'],
                'file_name': f['file_name'],
                'matched_page_number': f['matched_page_number'],
                'matching_score': f['matching_score'],
                'stage2_status': f['stage2_status'],
                # Base64 åœ–ç‰‡ï¼ˆå¯é¸æ“‡æ€§è¿”å›ç¸®åœ–ï¼‰
                'has_image': bool(f['matched_page_base64'])
            })

        return {"success": True, "files": preview_data}

    except Exception as e:
        return {"success": False, "error": str(e)}

@app.get("/api/batch-tasks/{task_id}/export")
async def export_task_to_excel(task_id: str):
    """åŒ¯å‡ºä»»å‹™çµæœç‚º Excel (åˆ†æ‰¹è™•ç†é¿å…è¨˜æ†¶é«”éè¼‰)"""
    try:
        from fastapi.responses import StreamingResponse
        import openpyxl
        from openpyxl.styles import Font, Alignment, PatternFill
        from io import BytesIO

        # å–å¾—ä»»å‹™è³‡è¨Š
        task = batch_db.get_task_by_id(task_id)
        if not task:
            return {"success": False, "error": "ä»»å‹™ä¸å­˜åœ¨"}

        # å–å¾—é—œéµå­—
        keywords = batch_db.get_task_keywords(task_id)

        # å‰µå»º Excel
        wb = openpyxl.Workbook()
        ws = wb.active
        ws.title = "OCR çµæœ"

        # è¨­å®šæ¨™é¡Œæ¨£å¼
        title_font = Font(bold=True, size=12)
        title_fill = PatternFill(start_color="CCE5FF", end_color="CCE5FF", fill_type="solid")
        title_alignment = Alignment(horizontal="center", vertical="center")

        # å¯«å…¥æ¨™é¡Œè¡Œ
        headers = ["æª”æ¡ˆåç¨±", "æª”æ¡ˆè·¯å¾‘", "ç‹€æ…‹", "åŒ¹é…é é¢", "åŒ¹é…åˆ†æ•¸"]
        headers.extend(keywords)
        headers.extend(["è™•ç†æ™‚é–“", "éŒ¯èª¤è¨Šæ¯"])

        # åˆå§‹åŒ–æ¬„å¯¬è¿½è¹¤å­—å…¸ (é¿å…å¾ŒçºŒéæ­·æ‰€æœ‰å„²å­˜æ ¼)
        column_widths = {}

        for col_idx, header in enumerate(headers, start=1):
            cell = ws.cell(row=1, column=col_idx, value=header)
            cell.font = title_font
            cell.fill = title_fill
            cell.alignment = title_alignment
            # åˆå§‹åŒ–æ¬„å¯¬ç‚ºæ¨™é¡Œé•·åº¦
            column_widths[col_idx] = len(str(header))

        # åˆ†æ‰¹è™•ç†æª”æ¡ˆè³‡æ–™,é¿å…ä¸€æ¬¡è¼‰å…¥éå¤šè¨˜æ†¶é«”
        batch_size = 100
        offset = 0
        row_idx = 2

        while True:
            # æ¯æ¬¡åªè¼‰å…¥ 100 ç­†è³‡æ–™,æ’é™¤ Base64 åœ–ç‰‡å’Œ OCR åŸå§‹çµæœä»¥æå‡æ•ˆèƒ½
            files = batch_db.get_task_files(
                task_id,
                limit=batch_size,
                offset=offset,
                exclude_base64=True,
                exclude_ocr_result=True  # åŒ¯å‡ºæ™‚ä¸éœ€è¦ OCR åŸå§‹çµæœ,åªéœ€è¦æå–çš„é—œéµå­—
            )

            if not files:
                break

            # å¯«å…¥é€™æ‰¹è³‡æ–™
            for file_info in files:
                # æ¬„ä½å€¼åˆ—è¡¨
                values = [
                    file_info['file_name'],
                    file_info['file_path'],
                    file_info['status'],
                    file_info['matched_page_number'],
                    file_info['matching_score']
                ]

                # è§£ææå–çš„é—œéµå­—
                extracted_keywords = {}
                if file_info['extracted_keywords']:
                    try:
                        extracted_keywords = json.loads(file_info['extracted_keywords'])
                    except (json.JSONDecodeError, TypeError, ValueError):  # nosec B110
                        # å¦‚æœç„¡æ³•è§£æ JSONï¼Œä¿æŒç©ºå­—å…¸
                        pass

                # æ·»åŠ é—œéµå­—å€¼
                for keyword in keywords:
                    values.append(extracted_keywords.get(keyword, ""))

                # æ·»åŠ è™•ç†æ™‚é–“å’ŒéŒ¯èª¤è¨Šæ¯
                values.append(file_info['processed_at'])
                values.append(file_info['error_message'])

                # å¯«å…¥å„²å­˜æ ¼ä¸¦åŒæ­¥æ›´æ–°æ¬„å¯¬
                for col_idx, value in enumerate(values, start=1):
                    ws.cell(row=row_idx, column=col_idx, value=value)
                    # åŒæ­¥è¿½è¹¤æœ€å¤§æ¬„å¯¬
                    value_length = len(str(value)) if value is not None else 0
                    if value_length > column_widths.get(col_idx, 0):
                        column_widths[col_idx] = value_length

                row_idx += 1

            offset += batch_size

            # å¦‚æœé€™æ‰¹è³‡æ–™å°‘æ–¼ batch_size,è¡¨ç¤ºå·²ç¶“æ˜¯æœ€å¾Œä¸€æ‰¹
            if len(files) < batch_size:
                break

        # å¥—ç”¨æ¬„å¯¬ (ä¸€æ¬¡æ€§è¨­å®š,é¿å…éæ­·æ‰€æœ‰å„²å­˜æ ¼)
        from openpyxl.utils import get_column_letter
        for col_idx, max_length in column_widths.items():
            # è¨­å®šåˆç†çš„æ¬„å¯¬ç¯„åœ: æœ€å° 10, æœ€å¤§ 50, é¡å¤–ç•™ 2 å€‹å­—å…ƒç©ºé–“
            adjusted_width = min(max(max_length + 2, 10), 50)
            column_letter = get_column_letter(col_idx)
            ws.column_dimensions[column_letter].width = adjusted_width

        # ä¿å­˜åˆ°å…§å­˜
        output = BytesIO()
        wb.save(output)
        output.seek(0)

        # è¿”å›æ–‡ä»¶ - ä½¿ç”¨URLç·¨ç¢¼è™•ç†ä¸­æ–‡æª”å
        filename = f"{task['task_name']}_{task_id[:8]}.xlsx"
        encoded_filename = quote(filename)
        return StreamingResponse(
            output,
            media_type="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            headers={"Content-Disposition": f"attachment; filename*=UTF-8''{encoded_filename}"}
        )

    except Exception as e:
        import traceback
        return {"success": False, "error": f"åŒ¯å‡ºå¤±æ•—: {str(e)}\n{traceback.format_exc()}"}

@app.get("/health")
async def health_check():
    """å¥åº·æª¢æŸ¥ç«¯é»"""
    return {"status": "healthy", "message": "PaddleOCR æœå‹™é‹è¡Œæ­£å¸¸"}

@app.get("/health/logs")
async def log_health_check():
    """æ—¥èªŒå¥åº·æª¢æŸ¥ç«¯é»"""
    try:
        from log_monitor import LogMonitor

        monitor = LogMonitor()
        result = monitor.check_log_health()
        summary = monitor.get_status_summary()

        return {
            "success": True,
            "health_check": result,
            "summary": summary
        }
    except Exception as e:
        logger.error(f"æ—¥èªŒå¥åº·æª¢æŸ¥å¤±æ•—: {e}", exc_info=True)
        return {
            "success": False,
            "error": str(e)
        }

@app.post("/admin/cleanup")
async def trigger_data_cleanup(dry_run: bool = False):
    """è§¸ç™¼è³‡æ–™æ¸…ç†ä½œæ¥­"""
    try:
        from data_retention import DataCleanupManager

        logger.info(f"æ”¶åˆ°è³‡æ–™æ¸…ç†è«‹æ±‚ (dry_run={dry_run})")
        manager = DataCleanupManager(dry_run=dry_run)
        result = manager.cleanup_all()

        logger.info(f"è³‡æ–™æ¸…ç†å®Œæˆ: åˆªé™¤ {result['summary']['total_deleted']} é …, é‡‹æ”¾ {result['summary']['total_freed_mb']:.2f} MB")

        return {
            "success": True,
            "result": result
        }
    except Exception as e:
        logger.error(f"è³‡æ–™æ¸…ç†å¤±æ•—: {e}", exc_info=True)
        return {
            "success": False,
            "error": str(e)
        }

@app.get("/admin/retention-policy")
async def get_retention_policy():
    """å–å¾—è³‡æ–™ä¿å­˜æ”¿ç­–"""
    try:
        from data_retention import RetentionPolicy

        policy = RetentionPolicy()
        return {
            "success": True,
            "policies": policy.policies
        }
    except Exception as e:
        return {
            "success": False,
            "error": str(e)
        }

@app.post("/admin/retention-policy")
async def update_retention_policy(policies: dict):
    """æ›´æ–°è³‡æ–™ä¿å­˜æ”¿ç­–"""
    try:
        from data_retention import RetentionPolicy

        policy = RetentionPolicy()
        for category, days in policies.items():
            policy.set_retention_days(category, int(days))
        policy.save_policies()

        logger.info(f"è³‡æ–™ä¿å­˜æ”¿ç­–å·²æ›´æ–°: {policies}")

        return {
            "success": True,
            "message": "ä¿å­˜æ”¿ç­–å·²æ›´æ–°"
        }
    except Exception as e:
        logger.error(f"æ›´æ–°ä¿å­˜æ”¿ç­–å¤±æ•—: {e}", exc_info=True)
        return {
            "success": False,
            "error": str(e)
        }

if __name__ == "__main__":
    import uvicorn
    import os

    # å¾ç’°å¢ƒè®Šé‡è®€å–é…ç½®ï¼Œé»˜èªåªç¶å®š localhost
    # ç”Ÿç”¢ç’°å¢ƒè‹¥éœ€è¦å°å¤–è¨ªå•ï¼Œè«‹è¨­ç½®ç’°å¢ƒè®Šé‡ APP_HOST=0.0.0.0
    host = os.getenv("APP_HOST", "127.0.0.1")
    port = int(os.getenv("APP_PORT", "8080"))

    print("ğŸš€ å•Ÿå‹• PaddleOCR ç¶²ç«™æœå‹™...")
    print(f"ğŸŒ æœå‹™åœ°å€: http://{host}:{port}")
    print(f"ğŸŒ æœ¬æ©Ÿè¨ªå•: http://localhost:{port}")
    print(f"ğŸ› ï¸ ç®¡ç†å¾Œå°: http://localhost:{port}/admin")

    # nosec B104: å¾ç’°å¢ƒè®Šé‡è®€å– hostï¼Œé»˜èªç‚ºå®‰å…¨çš„ 127.0.0.1
    # åªæœ‰æ˜ç¢ºè¨­ç½®ç’°å¢ƒè®Šé‡æ‰æœƒç¶å®šåˆ°æ‰€æœ‰æ¥å£ï¼Œä¸¦æœƒé¡¯ç¤ºè­¦å‘Š
    if host == "0.0.0.0":  # nosec B104
        print("âš ï¸  è­¦å‘Š: æœå‹™ç¶å®šåˆ°æ‰€æœ‰ç¶²çµ¡æ¥å£ (0.0.0.0)ï¼Œè«‹ç¢ºä¿å·²è¨­ç½®é©ç•¶çš„é˜²ç«ç‰†è¦å‰‡")

    uvicorn.run(app, host=host, port=port)